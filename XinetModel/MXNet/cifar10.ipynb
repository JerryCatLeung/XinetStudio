{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSRA初始化\n",
    "“Xavier” 是一种相对不错的初始化方法，在博文[“深度学习——Xavier初始化方法”](https://blog.csdn.net/shuzfan/article/details/51338178)中有介绍。但是，Xavier推导的时候假设激活函数是线性的，显然我们目前常用的ReLU和PReLU并不满足这一条件。\n",
    "\n",
    "只考虑输入个数时，[MSRA](https://blog.csdn.net/shuzfan/article/details/51347572) 初始化是一个均值为`0`方差为`2/n`的高斯分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:32:55.409356Z",
     "start_time": "2018-04-26T10:32:47.911365Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\cntk\\default_options.py:89: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() or inspect.getfullargspec()\n",
      "  args, _, _, _ = getargspec(function_or_class) if isfunction(function_or_class) else getargspec(function_or_class.__init__)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('E:/xinlib')\n",
    "import numpy as np\n",
    "import xint\n",
    "import imagex\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, autograd, nd, image\n",
    "from mxnet.gluon import nn\n",
    "from frameworkx import Residual, Inception, InceptionTranspose\n",
    "T = xint.Trainer('cifar10', 'ker2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:47:38.864842Z",
     "start_time": "2018-04-26T10:47:38.833842Z"
    }
   },
   "outputs": [],
   "source": [
    "def vgg_block(num_convs, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1):\n",
    "    '''\n",
    "    将 Inception 作为基础单元\n",
    "    '''\n",
    "    out = nn.HybridSequential()\n",
    "    for _ in range(num_convs):\n",
    "        out.add(Inception(n1_1, n2_1, n2_3, n3_1, n3_5, n4_1))\n",
    "    out.add(nn.MaxPool2D(pool_size=2, strides=2))\n",
    "    return out\n",
    "\n",
    "def vgg_stack(architecture):\n",
    "    out = nn.HybridSequential()\n",
    "    for (num_convs, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1) in architecture:\n",
    "        out.add(vgg_block(num_convs, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1))\n",
    "    return out\n",
    "\n",
    "def vgg_block_transpose(num_convs, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1):\n",
    "    '''\n",
    "    将 Inception 作为基础单元\n",
    "    '''\n",
    "    out = nn.HybridSequential()\n",
    "    channels = sum([n1_1, n2_1, n2_3, n3_1, n3_5, n4_1])\n",
    "    for _ in range(num_convs):\n",
    "        out.add(InceptionTranspose(n1_1, n2_1, n2_3, n3_1, n3_5, n4_1))\n",
    "    out.add(nn.Conv2DTranspose(channels, kernel_size=3, strides=2))\n",
    "    return out\n",
    "\n",
    "def vgg_stack_transpose(architecture):\n",
    "    out = nn.HybridSequential()\n",
    "    for (num_convs, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1) in architecture:\n",
    "        out.add(vgg_block_transpose(num_convs, n1_1, n2_1, n2_3, n3_1, n3_5, n4_1))\n",
    "    return out\n",
    "\n",
    "class NIN(Residual):\n",
    "    def __init__(self, n_classes, same_shape=False, **kwargs):\n",
    "        super().__init__(n_classes, same_shape, **kwargs)\n",
    "        self.architecture = ([2, 64, 96, 128, 16,32, 32],\n",
    "                             [2, 128, 128, 192, 32, 96, 64])\n",
    "        # add name_scope on the outermost Sequential\n",
    "        self.net = nn.HybridSequential()\n",
    "        with self.net.name_scope():\n",
    "            self.net.add(\n",
    "                vgg_stack(self.architecture),\n",
    "                vgg_stack_transpose(self.architecture)\n",
    "            )\n",
    "            \n",
    "    def hybrid_forward(self, F, x):\n",
    "        x = self.net(x)\n",
    "        out = self.conv1(F.relu(self.bn1(x)))\n",
    "        out = self.conv2(F.relu(self.bn2(out)))\n",
    "        if not self.same_shape:\n",
    "            x = self.conv3(x)\n",
    "        return F.relu(out + x)\n",
    "    \n",
    "n_out = 10\n",
    "n_classes = 10\n",
    "nin = NIN(n_classes)\n",
    "net = nn.HybridSequential()\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        nin,\n",
    "        nn.GlobalAvgPool2D(),\n",
    "        nn.Flatten()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:47:39.391358Z",
     "start_time": "2018-04-26T10:47:39.351360Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ctx = xint.try_gpu()\n",
    "#net.initialize(ctx=ctx, init=mx.init.Xavier())\n",
    "# net.initialize(ctx=ctx)\n",
    "#net.collect_params().initialize(mx.init.Normal(sigma=1), force_reinit=True, ctx=ctx)\n",
    "#net.hybridize()\n",
    "net.initialize(ctx=ctx, init=mx.init.MSRAPrelu())\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adadelta', {'rho': 0.9999})\n",
    "#trainer = gluon.Trainer(net.collect_params(), 'rmsprop', {'learning_rate': 0.03, 'gamma1': 0.9})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T10:47:53.521147Z",
     "start_time": "2018-04-26T10:47:39.885890Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.43572974  0.01842342  1.19811356  1.88724983  0.63832462  0.07957593\n",
       "   0.186563    0.49870616  1.03893507  0.23245613]\n",
       " [ 0.45598537  0.0168838   1.20165849  1.81312335  0.66502327  0.07044569\n",
       "   0.19124216  0.51440835  1.05111003  0.24925552]\n",
       " [ 0.44281268  0.01399717  1.17827344  1.82457972  0.68310964  0.07071031\n",
       "   0.18550892  0.46888238  1.08558524  0.2566174 ]\n",
       " [ 0.42326882  0.02013076  1.21423066  1.82286823  0.63406026  0.07462503\n",
       "   0.19891061  0.47036207  1.03869963  0.24199761]\n",
       " [ 0.3828238   0.01104463  1.18613124  1.88961053  0.65691543  0.07851652\n",
       "   0.18865846  0.47797817  1.06256902  0.25104168]\n",
       " [ 0.42719051  0.01636644  1.26936889  1.9372834   0.67934418  0.08098178\n",
       "   0.20867838  0.47962594  1.07578588  0.26137882]\n",
       " [ 0.42646083  0.01904831  1.15397274  1.76943862  0.66254437  0.05828552\n",
       "   0.19082645  0.46244949  1.03061473  0.22139737]\n",
       " [ 0.47132403  0.01518754  1.21396124  1.86598229  0.67295557  0.07046261\n",
       "   0.18220125  0.46621826  1.08331347  0.25238636]\n",
       " [ 0.44668418  0.0183674   1.25150192  1.87484968  0.67622972  0.07173479\n",
       "   0.19539513  0.49193329  1.06911325  0.23574683]\n",
       " [ 0.43252456  0.02222625  1.23249078  1.89906251  0.68718785  0.07707196\n",
       "   0.19272684  0.5221197   1.07672453  0.24851502]\n",
       " [ 0.43873894  0.01741153  1.24489629  1.87051487  0.69478393  0.06438833\n",
       "   0.19709343  0.49330714  1.02847254  0.25462583]\n",
       " [ 0.40479943  0.0171041   1.23143077  1.82541895  0.66222805  0.07141034\n",
       "   0.1853893   0.47607931  1.04123104  0.2346599 ]\n",
       " [ 0.4705551   0.01872527  1.2274102   1.90863109  0.70362961  0.08211809\n",
       "   0.18522491  0.50189161  1.08350801  0.25196654]\n",
       " [ 0.46123943  0.02047903  1.21686232  1.81165361  0.66044706  0.06468528\n",
       "   0.18696199  0.49508101  1.04349291  0.24992688]\n",
       " [ 0.44458869  0.01673352  1.20298243  1.82247674  0.66426784  0.07313643\n",
       "   0.20137186  0.48758858  1.07289684  0.24188191]\n",
       " [ 0.47374296  0.01713358  1.19230294  1.84306765  0.66022378  0.06708629\n",
       "   0.19388637  0.47965267  1.03834486  0.25366431]\n",
       " [ 0.48078278  0.00844202  1.18112838  1.80729783  0.6644997   0.07289244\n",
       "   0.18764903  0.49209049  1.02472055  0.24198462]\n",
       " [ 0.47550038  0.01069525  1.21679676  1.91202664  0.69728494  0.07893115\n",
       "   0.20041426  0.52043855  1.12357521  0.24083981]\n",
       " [ 0.44838315  0.01552302  1.20684254  1.85439897  0.68519843  0.07228907\n",
       "   0.19447577  0.5378359   1.11369741  0.2425019 ]\n",
       " [ 0.39595804  0.01711408  1.17878366  1.81623673  0.65412921  0.07542652\n",
       "   0.17747664  0.47806239  1.03928483  0.24004065]\n",
       " [ 0.44980344  0.02224982  1.17197239  1.77048898  0.66794342  0.07830477\n",
       "   0.19714999  0.51867461  1.0311054   0.21037094]\n",
       " [ 0.47719055  0.01561731  1.21943009  1.86099601  0.67664087  0.08210273\n",
       "   0.1980989   0.46362987  1.04665291  0.2722936 ]\n",
       " [ 0.45813441  0.01772309  1.16834235  1.7954582   0.6812185   0.06515066\n",
       "   0.18966287  0.51149482  1.06139314  0.25143081]\n",
       " [ 0.4098886   0.01592672  1.22480917  1.83008981  0.66312766  0.07396775\n",
       "   0.17673756  0.47398919  1.0581969   0.2282307 ]\n",
       " [ 0.4125531   0.01358401  1.21313727  1.81719494  0.68762618  0.07857741\n",
       "   0.19847172  0.48902616  1.05184484  0.24315602]\n",
       " [ 0.40713948  0.01874308  1.22015905  1.88279271  0.65716571  0.07048947\n",
       "   0.17959031  0.48593357  1.05497491  0.24191354]\n",
       " [ 0.44555995  0.01923622  1.20418096  1.87338579  0.67308611  0.06222719\n",
       "   0.19805798  0.46163803  1.01700234  0.24781746]\n",
       " [ 0.44976464  0.01471001  1.22104537  1.89131618  0.69364601  0.07962997\n",
       "   0.19232017  0.50414413  1.10694659  0.25121939]\n",
       " [ 0.46469167  0.02460035  1.17267525  1.77199435  0.65304995  0.07074514\n",
       "   0.1709664   0.49256378  1.07022488  0.23667993]\n",
       " [ 0.43496454  0.01933371  1.21873975  1.8629576   0.67369461  0.08397456\n",
       "   0.18575245  0.45988548  1.07280374  0.24996766]\n",
       " [ 0.49023533  0.0235022   1.21157289  1.80638409  0.65442443  0.07433094\n",
       "   0.18530315  0.52395165  1.04721785  0.24241325]\n",
       " [ 0.44023463  0.01788549  1.19534302  1.76046324  0.62389326  0.06861119\n",
       "   0.19636123  0.44936705  1.01035154  0.23971549]\n",
       " [ 0.46030253  0.01088192  1.22050631  1.81053615  0.67355931  0.07076849\n",
       "   0.19948003  0.48829368  1.04652512  0.28511614]\n",
       " [ 0.44734117  0.01705302  1.17618835  1.7311933   0.67277235  0.07324307\n",
       "   0.18895857  0.48865485  1.01386774  0.23482254]\n",
       " [ 0.42407894  0.02443277  1.20569813  1.83522904  0.66371512  0.06732651\n",
       "   0.16630676  0.49384511  1.02805805  0.24370044]\n",
       " [ 0.3907851   0.01363607  1.18681395  1.8556298   0.66889381  0.0690444\n",
       "   0.18477258  0.48805287  1.02731371  0.25172874]\n",
       " [ 0.44585773  0.0175588   1.16291285  1.79936349  0.68938494  0.0824168\n",
       "   0.18378808  0.48622674  1.0625788   0.23295557]\n",
       " [ 0.42339477  0.01807607  1.18489051  1.8873018   0.67102581  0.08471965\n",
       "   0.18432114  0.48549378  1.07511342  0.22624527]\n",
       " [ 0.42980558  0.02217574  1.22446609  1.90295446  0.6879822   0.0794435\n",
       "   0.19389942  0.48122382  1.07257771  0.24911946]\n",
       " [ 0.4817695   0.02215614  1.21472108  1.86066544  0.66497153  0.07701872\n",
       "   0.18965781  0.52723289  1.09579885  0.23568523]\n",
       " [ 0.42575347  0.01674125  1.18846202  1.84816599  0.67400217  0.07109579\n",
       "   0.18404716  0.49761266  1.07910252  0.23166198]\n",
       " [ 0.44684505  0.01630572  1.18585134  1.88164282  0.70847571  0.09682861\n",
       "   0.20221303  0.51360917  1.08280873  0.24162245]\n",
       " [ 0.44876888  0.01631836  1.23908961  1.8740654   0.66909695  0.08186127\n",
       "   0.19604038  0.47809392  1.07720065  0.23328201]\n",
       " [ 0.46721536  0.0232795   1.21357739  1.86760378  0.70170236  0.07894034\n",
       "   0.19088075  0.4837524   1.0647608   0.23442905]\n",
       " [ 0.41535902  0.0163712   1.13626659  1.75993013  0.64842552  0.06587615\n",
       "   0.16680509  0.47742033  1.01575267  0.22645655]\n",
       " [ 0.44899195  0.02153074  1.19791019  1.85842955  0.66941422  0.08541887\n",
       "   0.18603168  0.50786638  1.07372105  0.2423618 ]\n",
       " [ 0.45438054  0.01304261  1.21755314  1.97333252  0.68161893  0.08008588\n",
       "   0.20023365  0.50711292  1.14252985  0.27170148]\n",
       " [ 0.41861743  0.01462208  1.24529421  1.88209558  0.65095109  0.07626063\n",
       "   0.20045796  0.47805503  1.09604883  0.22525321]\n",
       " [ 0.45445821  0.02714385  1.28215289  1.83523083  0.68895197  0.07286415\n",
       "   0.17625564  0.50121605  1.11093473  0.26259917]\n",
       " [ 0.41964439  0.01602606  1.19806945  1.85673106  0.70035881  0.07860143\n",
       "   0.18383367  0.46323186  1.01052177  0.24782749]\n",
       " [ 0.39165744  0.01716973  1.21399415  1.85580862  0.66596055  0.08030208\n",
       "   0.19232354  0.46320766  1.05152059  0.26227874]\n",
       " [ 0.41402015  0.02394609  1.23832357  1.83600187  0.67842638  0.07362524\n",
       "   0.19239883  0.49177974  1.01658154  0.25163612]\n",
       " [ 0.44575694  0.01368198  1.18829858  1.89031911  0.68451297  0.07652439\n",
       "   0.18710318  0.48669428  1.10042226  0.23986764]\n",
       " [ 0.4450388   0.01696362  1.24668145  1.86113167  0.67944556  0.06473459\n",
       "   0.18328625  0.52599883  1.06825745  0.23828678]\n",
       " [ 0.41594592  0.02003732  1.20199251  1.81712818  0.66328114  0.08073556\n",
       "   0.20000011  0.4878979   1.02001309  0.22304653]\n",
       " [ 0.45385808  0.01788109  1.23575342  1.89420605  0.66381645  0.08333868\n",
       "   0.18292439  0.4889195   1.11944127  0.2439359 ]\n",
       " [ 0.42205411  0.01255566  1.20268941  1.83276343  0.68992442  0.08396333\n",
       "   0.18010777  0.47707641  1.07067084  0.24661325]\n",
       " [ 0.41560954  0.01620498  1.2369647   1.79561496  0.67287344  0.06914179\n",
       "   0.18771945  0.491779    1.04960525  0.25706241]\n",
       " [ 0.42569506  0.02337538  1.22726703  1.84985828  0.64911103  0.06569123\n",
       "   0.17723961  0.49095917  1.01785016  0.22733051]\n",
       " [ 0.39905265  0.01467378  1.23224425  1.8192476   0.69829607  0.07690288\n",
       "   0.19169535  0.51959574  1.00503182  0.25279641]\n",
       " [ 0.45989496  0.02026224  1.21426141  1.82375801  0.6311698   0.07254992\n",
       "   0.19993705  0.49199492  1.04576612  0.24490039]\n",
       " [ 0.4483456   0.01663644  1.22063196  1.85801542  0.66570193  0.07731657\n",
       "   0.19638804  0.4972139   1.04407609  0.24334154]\n",
       " [ 0.46555009  0.01934305  1.16382051  1.7904098   0.63518518  0.08175475\n",
       "   0.18493728  0.48624817  1.06004131  0.23539568]\n",
       " [ 0.43159598  0.02212787  1.18253887  1.79533064  0.63656789  0.06606237\n",
       "   0.18816531  0.49064261  1.03103495  0.21204698]\n",
       " [ 0.43503401  0.00991548  1.16000998  1.80510533  0.69249386  0.07242525\n",
       "   0.18987738  0.49348679  1.01987565  0.24053526]\n",
       " [ 0.40969613  0.01045697  1.20890427  1.81671762  0.67445248  0.08161706\n",
       "   0.19334973  0.47962543  1.04979193  0.22932695]\n",
       " [ 0.47716427  0.0172453   1.22999501  1.87926102  0.72796297  0.08221973\n",
       "   0.19381577  0.45878381  1.05090559  0.2538518 ]\n",
       " [ 0.39195284  0.01941517  1.21361566  1.81746101  0.65530729  0.07432939\n",
       "   0.17736241  0.45267764  1.02107418  0.25222233]\n",
       " [ 0.41467902  0.01682626  1.18715417  1.85376668  0.66445535  0.07884164\n",
       "   0.18546514  0.49156976  1.10436773  0.21477152]\n",
       " [ 0.46794882  0.01498844  1.18905675  1.87203717  0.69547814  0.06914762\n",
       "   0.20608568  0.52664632  1.09899795  0.22926006]\n",
       " [ 0.4372665   0.02110828  1.22222126  1.89667141  0.66788346  0.07779073\n",
       "   0.20411894  0.49618912  1.07392728  0.25800082]\n",
       " [ 0.43633977  0.01353786  1.19380081  1.85665476  0.67516476  0.07859389\n",
       "   0.19230078  0.51577997  1.0680902   0.25515047]\n",
       " [ 0.41638184  0.01828214  1.2112627   1.82196331  0.66728508  0.08033708\n",
       "   0.18755114  0.49207437  1.04829872  0.24594103]\n",
       " [ 0.43881074  0.01546511  1.22534859  1.89426041  0.68116969  0.077851\n",
       "   0.19431511  0.49443257  1.09299839  0.26275718]\n",
       " [ 0.43694368  0.01754849  1.17605615  1.86944938  0.67357761  0.07370237\n",
       "   0.20718756  0.47632942  1.05701292  0.25116155]\n",
       " [ 0.43446478  0.01604285  1.26264799  1.90692234  0.68391109  0.06798503\n",
       "   0.19776186  0.50308102  1.11233258  0.26790106]\n",
       " [ 0.43928027  0.02325858  1.18901122  1.83696401  0.68198156  0.08019605\n",
       "   0.19397058  0.47895536  1.06445026  0.24844141]\n",
       " [ 0.45783487  0.01706337  1.19271553  1.84281075  0.66199684  0.07588558\n",
       "   0.18100221  0.47883689  1.06978881  0.217104  ]\n",
       " [ 0.43262711  0.01433378  1.1668129   1.85140049  0.66314864  0.07635489\n",
       "   0.17268813  0.47206846  1.07215524  0.22279958]\n",
       " [ 0.41773394  0.01587648  1.20693433  1.88049603  0.64018089  0.07172998\n",
       "   0.19922021  0.49064547  1.00294709  0.24250104]\n",
       " [ 0.41869876  0.01927393  1.20770967  1.80775487  0.64282715  0.0782989\n",
       "   0.21011661  0.49940619  1.03761268  0.26405033]\n",
       " [ 0.42767286  0.01778934  1.20157468  1.84021103  0.69305217  0.07807876\n",
       "   0.19439465  0.48597217  1.06640875  0.21809687]\n",
       " [ 0.43803892  0.01580201  1.16878033  1.81468356  0.68387121  0.07400755\n",
       "   0.18083617  0.47685269  1.05046308  0.2338444 ]\n",
       " [ 0.44758198  0.01966552  1.15344214  1.7972939   0.66204488  0.07919851\n",
       "   0.19201812  0.50730801  0.994084    0.24642   ]\n",
       " [ 0.48296714  0.01838848  1.22115076  1.79748333  0.65972662  0.07118236\n",
       "   0.20337555  0.4917427   1.12034428  0.22247595]\n",
       " [ 0.42229754  0.01756615  1.25403416  1.90422356  0.67193639  0.06364395\n",
       "   0.20044871  0.51587296  1.07880306  0.25074661]\n",
       " [ 0.45907918  0.01329189  1.20921218  1.8331821   0.67313117  0.08260517\n",
       "   0.18515199  0.47229183  1.05293918  0.25731704]\n",
       " [ 0.45952827  0.01580339  1.21311843  1.86356795  0.67344141  0.08453707\n",
       "   0.18626849  0.48928499  1.0727272   0.238736  ]\n",
       " [ 0.44233677  0.01704183  1.21589673  1.89381433  0.66557789  0.08322489\n",
       "   0.17799991  0.50270236  1.10137033  0.22617072]\n",
       " [ 0.46337882  0.01991378  1.22165847  1.87220478  0.69025993  0.08773682\n",
       "   0.20057118  0.51921314  1.10261679  0.24163884]\n",
       " [ 0.44044739  0.02595542  1.23919261  1.86160374  0.7035324   0.07853417\n",
       "   0.20129123  0.5172165   1.02431548  0.26094306]\n",
       " [ 0.41018784  0.01615304  1.22486186  1.82849705  0.66619444  0.07307706\n",
       "   0.19501732  0.47881278  1.04752064  0.23443867]\n",
       " [ 0.43625495  0.01509349  1.16121173  1.8295989   0.65222734  0.07258283\n",
       "   0.18709719  0.48098335  1.02435327  0.23909292]\n",
       " [ 0.43447593  0.01427849  1.20345473  1.81675327  0.65212244  0.07531975\n",
       "   0.18913154  0.47319418  1.0503397   0.22911657]\n",
       " [ 0.45190763  0.01302715  1.22462702  1.88138795  0.69040108  0.08138552\n",
       "   0.1922722   0.49299881  1.07079875  0.24301392]\n",
       " [ 0.46055847  0.01828325  1.2056216   1.85979807  0.71328843  0.08863063\n",
       "   0.17840384  0.48561478  1.05330908  0.23630451]\n",
       " [ 0.43141857  0.01924245  1.21628678  1.85222995  0.69085616  0.07071461\n",
       "   0.19275323  0.50403231  1.05261207  0.23208618]\n",
       " [ 0.43513861  0.01983086  1.26207542  1.86644948  0.66844201  0.080046\n",
       "   0.18314739  0.49964735  1.10406685  0.26596564]\n",
       " [ 0.45260751  0.01728703  1.1718297   1.89399195  0.69907844  0.07872161\n",
       "   0.20186125  0.50938493  1.12911785  0.22295563]\n",
       " [ 0.44304618  0.01573207  1.20163357  1.81429541  0.65526164  0.06637602\n",
       "   0.18228677  0.46872631  1.03455186  0.25672042]]\n",
       "<NDArray 100x10 @gpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = nd.random_normal(shape=(100, 3, 32, 32)).as_in_context(mx.gpu(0))\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-26T08:39:15.851422Z",
     "start_time": "2018-04-26T08:36:08.835010Z"
    }
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 64\n",
    "T.train(net, loss, trainer, num_epochs, batch_size, True, *[32, 28])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [【CV知识学习】神经网络梯度与归一化问题总结+highway network、ResNet的思考](http://www.cnblogs.com/jie-dcai/p/5803220.html)\n",
    "\n",
    "可以看到，当网络加深，训练的误差反而上升了，而加入了highway之后，这个问题得到了缓解。一般来说，深度网络训练困难是由于梯度回流受阻的问题，可能浅层网络没有办法得到调整，或者我自己YY的一个原因是（回流的信息经过网络之后已经变形了，很可能就出现了internal covariate shift类似的问题了）。Highway Network 受LSTM启发，增加了一个门函数，让网络的输出由两部分组成，分别是网络的直接输入以及输入变形后的部分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-25T06:07:25.767136Z",
     "start_time": "2018-04-25T06:07:25.751563Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
