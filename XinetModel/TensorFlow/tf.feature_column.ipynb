{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:27:48.021931Z",
     "start_time": "2018-04-02T14:27:42.338897Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.estimator.inputs import numpy_io\n",
    "import numpy as np\n",
    "import collections\n",
    "from tensorflow.python.framework import errors\n",
    "from tensorflow.python.platform import test\n",
    "from tensorflow.python.training import coordinator\n",
    "from tensorflow import feature_column\n",
    "\n",
    "from tensorflow.python.feature_column.feature_column import _LazyBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `numeric_column`\n",
    "\n",
    "```py\n",
    "numeric_column(\n",
    "    key,\n",
    "    shape=(1,),\n",
    "    default_value=None,\n",
    "    dtype=tf.float32,\n",
    "    normalizer_fn=None\n",
    ")\n",
    "```\n",
    "\n",
    "- `key`: 特征的名字。也就是对应的列名称。\n",
    "- `shape`: 该`key`所对应的特征的`shape`. 默认是`1`，但是比如`one-hot`类型的，`shape`就不是`1`，而是实际的维度。总之，这里是`key`所对应的维度，不一定是`1`.\n",
    "- `default_value`: 如果不存在使用的默认值\n",
    "- `normalizer_fn`: 对该特征下的所有数据进行转换。如果需要进行`normalize`，那么就是使用`normalize`的函数.这里不仅仅局限于`normalize`，也可以是任何的转换方法，比如取对数，取指数，这仅仅是一种变换方法.\n",
    "\n",
    "接下来对 `numeric_column` 测试的demo如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:28:15.584077Z",
     "start_time": "2018-04-02T14:28:15.562049Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_numeric():\n",
    "\n",
    "    price = {'price': [[1.], [2.], [3.], [4.]]}  # 4行样本\n",
    "    builder = _LazyBuilder(price)\n",
    "\n",
    "    def transform_fn(x):\n",
    "        return x + 2\n",
    "\n",
    "    price_column = feature_column.numeric_column(\n",
    "        'price', normalizer_fn=transform_fn)\n",
    "\n",
    "    price_transformed_tensor = price_column._get_dense_tensor(builder)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        print(session.run([price_transformed_tensor]))\n",
    "\n",
    "    # 使用input_layer\n",
    "\n",
    "    price_transformed_tensor = feature_column.input_layer(price, [\n",
    "                                                          price_column])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([price_transformed_tensor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:28:22.888128Z",
     "start_time": "2018-04-02T14:28:19.163125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 3.],\n",
      "       [ 4.],\n",
      "       [ 5.],\n",
      "       [ 6.]], dtype=float32)]\n",
      "use input_layer________________________________________\n",
      "[array([[ 3.],\n",
      "       [ 4.],\n",
      "       [ 5.],\n",
      "       [ 6.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_numeric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面的结果可以看出，`transform_fn` 将所有的数值`+2`来处理了。使用`_LazyBuilder`和`inpu_layer`来分别进行了测试，效果是一样的."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `bucketized_column`\n",
    "```bucketized_column(source_column, boundaries)```\n",
    "\n",
    "- `source_column`: 必须是`numeric_column`\n",
    "- `boundaries`: 不同的桶。`boundaries=[0., 1., 2.]`,产生的`bucket`就是, `(-inf, 0.), [0., 1.), [1., 2.), and [2., +inf)`, 每一个区间分别表示`0`, `1`, `2`, `3`,所以相当于分桶分了`4`个."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:32:31.215838Z",
     "start_time": "2018-04-02T14:32:31.053841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.,  1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  1.,  0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def test_bucketized_column():\n",
    "\n",
    "    price = {'price': [[5.], [15.], [25.], [35.]]}  # 4行样本\n",
    "\n",
    "    price_column = feature_column.numeric_column('price')\n",
    "    bucket_price = feature_column.bucketized_column(\n",
    "        price_column, [0, 10, 20, 30, 40])\n",
    "\n",
    "    price_bucket_tensor = feature_column.input_layer(price, [bucket_price])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        print(session.run([price_bucket_tensor]))\n",
    "\n",
    "\n",
    "test_bucketized_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到分桶之后，会直接转换成`one-hot`m形式的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `categorical_column_with_vocabulary_list`\n",
    "```py\n",
    "categorical_column_with_vocabulary_list(\n",
    "    key,\n",
    "    vocabulary_list,\n",
    "    dtype=None,\n",
    "    default_value=-1,\n",
    "    num_oov_buckets=0\n",
    ")\n",
    "```\n",
    "- `key`: `feature`名字\n",
    "- `vocabulary_list`: 对于 `category` 来说，进行转换的`list`.也就是`category`列表.\n",
    "- `dtype`: 仅仅`string` 和 `int` 被支持，其他的类型是无法进行这个操作的.\n",
    "- `default_value`: 当不在`vocabulary_list`中的默认值，这时候`num_oov_buckets`必须是`0`.\n",
    "- `num_oov_buckets`: 用来处理那些不在`vocabulary_list` 中的值，如果是`0`，那么使用`default_value`进行填充;如果大于`0`，则会在`[len(vocabulary_list), len(vocabulary_list)+num_oov_buckets]`这个区间上重新计算当前特征的值.\n",
    "与前面 `numeric` 不同的是，这里返回的是稀疏`tensor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:35:42.136580Z",
     "start_time": "2018-04-02T14:35:42.073569Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_categorical_column_with_vocabulary_list():\n",
    "\n",
    "    color_data = {'color': [['R', 'R'], [\n",
    "        'G', 'R'], ['B', 'G'], ['A', 'A']]}  # 4行样本\n",
    "\n",
    "    builder = _LazyBuilder(color_data)\n",
    "\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "    )\n",
    "\n",
    "    color_column_tensor = color_column._get_sparse_tensors(builder)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print(session.run([color_column_tensor.id_tensor]))\n",
    "\n",
    "    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot\n",
    "    color_column_identy = feature_column.indicator_column(color_column)\n",
    "\n",
    "    color_dense_tensor = feature_column.input_layer(\n",
    "        color_data, [color_column_identy])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([color_dense_tensor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:35:47.065597Z",
     "start_time": "2018-04-02T14:35:46.173578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [0, 1],\n",
      "       [1, 0],\n",
      "       [1, 1],\n",
      "       [2, 0],\n",
      "       [2, 1],\n",
      "       [3, 0],\n",
      "       [3, 1]], dtype=int64), values=array([ 0,  0,  1,  0,  2,  1, -1, -1], dtype=int64), dense_shape=array([4, 2], dtype=int64))]\n",
      "use input_layer________________________________________\n",
      "[array([[ 2.,  0.,  0.],\n",
      "       [ 1.,  1.,  0.],\n",
      "       [ 0.,  1.,  1.],\n",
      "       [ 0.,  0.,  0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_categorical_column_with_vocabulary_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于`categorical_column_with_vocabulary_list`来说返回的是`sparser_tensor`，注意 `id_tensor` 这个是有效的，另外一个是`None`. 对于线性模型来说是可以直接使用`sparser_tensor`的。然而，对于深度模型来说，需要将`sparser`转换成`dense`，所以也就有了`indicator_column`这个函数的出现。`indicator_column`的作用就是将`category`产生的`sparser tensor`转换成`dense tensor`.\n",
    "\n",
    "注意: \n",
    "* `input_layer`: 只接受  `dense tensor` \n",
    "* `tables_initializer`: 在`sparser`的时候使用的，如果不进行初始化会出现 `Table not initialized`. `[Node: hash_table_Lookup = LookupTableFindV2` 这样的异常`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `categorical_column_with_hash_bucket`\n",
    "```py\n",
    "categorical_column_with_hash_bucket(\n",
    "    key,\n",
    "    hash_bucket_size,\n",
    "    dtype=tf.string\n",
    ")\n",
    "```\n",
    "\n",
    "当`category`的数量很多，也就无法使用指定`category`的方法来处理了，那么，可以使用这种哈希分桶的方式来进行处理。比如，切词之后的句子，每一个词可以使用这种方式来处理. 使用 `categorical_column_with_vocabulary_file` 也是一种不错的选择，比如将词频高的拿出来。毕竟对于`hash_bucket`来说，对于`bucket_size`的选取是个问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:38:51.831628Z",
     "start_time": "2018-04-02T14:38:51.794663Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_categorical_column_with_hash_bucket():\n",
    "\n",
    "    color_data = {'color': [['R'], ['G'], ['B'], ['A']]}  # 4行样本\n",
    "\n",
    "    builder = _LazyBuilder(color_data)\n",
    "\n",
    "    color_column = feature_column.categorical_column_with_hash_bucket(\n",
    "        'color', 7)\n",
    "\n",
    "    color_column_tensor = color_column._get_sparse_tensors(builder)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print(session.run([color_column_tensor.id_tensor]))\n",
    "\n",
    "    # 将稀疏的转换成dense，也就是one-hot形式，只是multi-hot\n",
    "    color_column_identy = feature_column.indicator_column(color_column)\n",
    "\n",
    "    color_dense_tensor = feature_column.input_layer(\n",
    "        color_data, [color_column_identy])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([color_dense_tensor]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:39:04.409634Z",
     "start_time": "2018-04-02T14:39:04.200656Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 0],\n",
      "       [3, 0]], dtype=int64), values=array([5, 2, 6, 3], dtype=int64), dense_shape=array([4, 1], dtype=int64))]\n",
      "use input_layer________________________________________\n",
      "[array([[ 0.,  0.,  0.,  0.,  0.,  1.,  0.],\n",
      "       [ 0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
      "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "test_categorical_column_with_hash_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面看这种`hash`分桶的方法，在`hash_size`的选择上是很重要的。现在选择`3`，对于 R 和 B 来说分桶到一个烈面了；对于 G 和 A 分桶到一个里面了。当将 `hash_size=7`来测试, R G B A 就都分到了不同的桶中，所以值越大也容易精确的分桶.\n",
    "\n",
    "# `categorical_column_with_identity`\n",
    "```py\n",
    "categorical_column_with_identity(\n",
    "    key,\n",
    "    num_buckets,\n",
    "    default_value=None\n",
    ")\n",
    "```\n",
    "\n",
    "这是对连续的数字类的处理函数。比如 `id` 一共有`10000`个，那么可以使用这种方式。但是如果多数没有被使用，那么还不如使用 `categorical_column_with_hash_bucket` 进行重新处理。\n",
    "\n",
    "# `embedding_column`\n",
    "```py\n",
    "embedding_column(\n",
    "    categorical_column,\n",
    "    dimension,\n",
    "    combiner='mean',\n",
    "    initializer=None,\n",
    "    ckpt_to_load_from=None,\n",
    "    tensor_name_in_ckpt=None,\n",
    "    max_norm=None,\n",
    "    trainable=True\n",
    ")\n",
    "```\n",
    "\n",
    "- `categorical_column`: 使用`categoryical_column`产生的`sparsor column`\n",
    "- `dimension`: 定义`embedding`的维数\n",
    "- `combiner`: 对于多个`entries`进行的推导。默认是`meam`, 但是 `sqrtn` 在词袋模型中，有更好的准确度。\n",
    "- `initializer`: 初始化方法，默认使用高斯分布来初始化。\n",
    "- `tensor_name_in_ckpt`: 可以从 check point 中恢复\n",
    "- `ckpt_to_load_from`: check point file，这是在 `tensor_name_in_ckpt` 不为空的情况下设置的.\n",
    "- `max_norm`: 默认是`l2`\n",
    "- `trainable`: 是否可训练的，默认是`True`\n",
    "将`sparsor tensor`转换成`dense tensor`. 在 DNN 的输入中需要使用`dense tensor`. `embedding`如果共用，需要的是`name`一样."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:43:51.886608Z",
     "start_time": "2018-04-02T14:43:51.598635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeding________________________________________\n",
      "[array([[ 0.17713186, -0.66315776,  0.57591653,  0.28331786,  0.28766611,\n",
      "        -0.44875047, -0.07845679,  0.0941939 ],\n",
      "       [-0.56759846,  0.2312403 , -0.10596016, -0.00640535, -0.31522641,\n",
      "        -0.05999918, -0.11839385,  0.26132873],\n",
      "       [-0.09545483,  0.55210358, -0.30541521, -0.07820553,  0.35961756,\n",
      "         0.0802813 ,  0.38947856, -0.17908967],\n",
      "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "         0.        ,  0.        ,  0.        ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "def test_embedding():\n",
    "    color_data = {'color': [['R'], ['G'], ['B'], ['A']]}  # 4行样本\n",
    "\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "    )\n",
    "\n",
    "    color_embeding = feature_column.embedding_column(color_column, 8)\n",
    "    color_embeding_dense_tensor = feature_column.input_layer(color_data, [\n",
    "                                                             color_embeding])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('embeding' + '_' * 40)\n",
    "        print(session.run([color_embeding_dense_tensor]))\n",
    "\n",
    "\n",
    "test_embedding()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每一个都会转换成8个维度的数据，并且使用高斯分布来进行初始化。因为A 没有在`catergorical_column`中出现，所以使用了`0`进行初始化.\n",
    "\n",
    "# `weighted_categorical_column`\n",
    "```py\n",
    "weighted_categorical_column(\n",
    "    categorical_column,\n",
    "    weight_feature_key,\n",
    "    dtype=tf.float32\n",
    ")\n",
    "```\n",
    "为`categorical_column`赋值权重。默认的`categorical_column`中，所有的权重都是一样的，但是有些时候，对于同样一组`category_column`不同的`category`的权重不同。例如，如果使用`tag`来表示文本，那么`tag`的权重就不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:45:20.567858Z",
     "start_time": "2018-04-02T14:45:20.415859Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weighted categorical----------------------------------------\n",
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 0],\n",
      "       [3, 0]], dtype=int64), values=array([ 0,  1,  2, -1], dtype=int64), dense_shape=array([4, 1], dtype=int64))]\n",
      "----------------------------------------\n",
      "[SparseTensorValue(indices=array([[0, 0],\n",
      "       [1, 0],\n",
      "       [2, 0],\n",
      "       [3, 0]], dtype=int64), values=array([ 1.,  2.,  4.,  8.], dtype=float32), dense_shape=array([4, 1], dtype=int64))]\n"
     ]
    }
   ],
   "source": [
    "def test_weighted_categorical_column():\n",
    "    color_data = {'color': [['R'], ['G'], ['B'], ['A']],\n",
    "                  'weight': [[1.0], [2.0], [4.0], [8.0]]}  # 4行样本\n",
    "\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list(\n",
    "        'color', ['R', 'G', 'B'], dtype=tf.string, default_value=-1\n",
    "    )\n",
    "\n",
    "    color_weight_categorical_column = feature_column.weighted_categorical_column(\n",
    "        color_column, 'weight')\n",
    "\n",
    "    builder = _LazyBuilder(color_data)\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        id_tensor, weight = color_weight_categorical_column._get_sparse_tensors(\n",
    "            builder)\n",
    "\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('weighted categorical' + '-' * 40)\n",
    "\n",
    "        print(session.run([id_tensor]))\n",
    "        print('-' * 40)\n",
    "        print(session.run([weight]))\n",
    "\n",
    "\n",
    "test_weighted_categorical_column()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，`weight` 这个 tensor 也是存在的。对于前面其他 `categorical_column` 来说是不存在 `weight` 的。\n",
    "\n",
    "# `linear_model`\n",
    "```py\n",
    "linear_model(\n",
    "    features,\n",
    "    feature_columns,\n",
    "    units=1,\n",
    "    sparse_combiner='sum',\n",
    "    weight_collections=None,\n",
    "    trainable=True\n",
    ")\n",
    "```\n",
    "对所有特征进行线性加权操作."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-02T14:47:11.435894Z",
     "start_time": "2018-04-02T14:47:09.250898Z"
    }
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Blas GEMV launch failed:  m=1, n=3\n\t [[Node: linear_model/price/weighted_sum = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](linear_model/price/Reshape, linear_model/price/weights/read)]]\n\t [[Node: linear_model/weighted_sum/_67 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_98_linear_model/weighted_sum\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'linear_model/price/weighted_sum', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-fce934b1a40e>\", line 46, in <module>\n    test_linear_model()\n  File \"<ipython-input-12-fce934b1a40e>\", line 26, in test_linear_model\n    featrues, [price_column, color_column])\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 433, in linear_model\n    trainable=trainable)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 1710, in _create_weighted_sum\n    trainable=trainable)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 1729, in _create_dense_column_weighted_sum\n    return math_ops.matmul(tensor, weight, name='weighted_sum')\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2108, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4492, in mat_mul\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMV launch failed:  m=1, n=3\n\t [[Node: linear_model/price/weighted_sum = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](linear_model/price/Reshape, linear_model/price/weights/read)]]\n\t [[Node: linear_model/weighted_sum/_67 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_98_linear_model/weighted_sum\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1327\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1328\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1312\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m             status, run_metadata)\n\u001b[0m\u001b[0;32m   1421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    517\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMV launch failed:  m=1, n=3\n\t [[Node: linear_model/price/weighted_sum = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](linear_model/price/Reshape, linear_model/price/weights/read)]]\n\t [[Node: linear_model/weighted_sum/_67 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_98_linear_model/weighted_sum\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-fce934b1a40e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mtest_linear_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-fce934b1a40e>\u001b[0m in \u001b[0;36mtest_linear_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mpredication_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredication_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1140\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1321\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1322\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1340\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMV launch failed:  m=1, n=3\n\t [[Node: linear_model/price/weighted_sum = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](linear_model/price/Reshape, linear_model/price/weights/read)]]\n\t [[Node: linear_model/weighted_sum/_67 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_98_linear_model/weighted_sum\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'linear_model/price/weighted_sum', defined at:\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1431, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-fce934b1a40e>\", line 46, in <module>\n    test_linear_model()\n  File \"<ipython-input-12-fce934b1a40e>\", line 26, in test_linear_model\n    featrues, [price_column, color_column])\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 433, in linear_model\n    trainable=trainable)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 1710, in _create_weighted_sum\n    trainable=trainable)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\", line 1729, in _create_dense_column_weighted_sum\n    return math_ops.matmul(tensor, weight, name='weighted_sum')\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 2108, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 4492, in mat_mul\n    name=name)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3290, in create_op\n    op_def=op_def)\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1654, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInternalError (see above for traceback): Blas GEMV launch failed:  m=1, n=3\n\t [[Node: linear_model/price/weighted_sum = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](linear_model/price/Reshape, linear_model/price/weights/read)]]\n\t [[Node: linear_model/weighted_sum/_67 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_98_linear_model/weighted_sum\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "def get_linear_model_bias():\n",
    "    with tf.variable_scope('linear_model', reuse=True):\n",
    "        return tf.get_variable('bias_weights')\n",
    "\n",
    "\n",
    "def get_linear_model_column_var(column):\n",
    "    return tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES,\n",
    "                             'linear_model/' + column.name)[0]\n",
    "\n",
    "\n",
    "def test_linear_model():\n",
    "    \"\"\"\n",
    "    测试线性模型\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    featrues = {\n",
    "        'price': [[1.0], [5.0], [10.0]],\n",
    "        'color': [['R'], ['G'], ['B']]\n",
    "    }\n",
    "\n",
    "    price_column = feature_column.numeric_column('price')\n",
    "    color_column = feature_column.categorical_column_with_vocabulary_list('color',\n",
    "                                                                          ['R', 'G', 'B'])\n",
    "    prediction = feature_column.linear_model(\n",
    "        featrues, [price_column, color_column])\n",
    "\n",
    "    bias = get_linear_model_bias()\n",
    "    price_var = get_linear_model_column_var(price_column)\n",
    "    color_var = get_linear_model_column_var(color_column)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(tf.local_variables_initializer())\n",
    "        sess.run(tf.tables_initializer())\n",
    "\n",
    "        sess.run(bias.assign([7.0]))\n",
    "        sess.run(price_var.assign([[10.0]]))\n",
    "        sess.run(color_var.assign([[2.0], [2.0], [2.0]]))\n",
    "\n",
    "        predication_result = sess.run([prediction])\n",
    "\n",
    "        print(predication_result)\n",
    "\n",
    "\n",
    "test_linear_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `crossed_column`\n",
    "组合特征，这仅仅适用于`sparser`特征.产生的依然是`sparsor`特征."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-02T14:49:20.803Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_crossed_column():\n",
    "    \"\"\"\n",
    "    crossed column测试\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    featrues = {\n",
    "        'price': [['A', 'A'], ['B', 'D'], ['C', 'A']],\n",
    "        'color': [['R', 'R'], ['G', 'G'], ['B', 'B']]\n",
    "    }\n",
    "\n",
    "    price = feature_column.categorical_column_with_vocabulary_list('price',\n",
    "                                                                   ['A', 'B', 'C', 'D'])\n",
    "    color = feature_column.categorical_column_with_vocabulary_list('color',\n",
    "                                                                   ['R', 'G', 'B'])\n",
    "    p_x_c = feature_column.crossed_column([price, color], 16)\n",
    "\n",
    "    p_x_c_identy = feature_column.indicator_column(p_x_c)\n",
    "\n",
    "    p_x_c_identy_dense_tensor = feature_column.input_layer(featrues, [\n",
    "                                                           p_x_c_identy])\n",
    "\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "\n",
    "        session.run(tf.tables_initializer())\n",
    "\n",
    "        print('use input_layer' + '_' * 40)\n",
    "        print(session.run([p_x_c_identy_dense_tensor]))\n",
    "\n",
    "\n",
    "test_crossed_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "267px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
