{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T11:16:29.299435Z",
     "start_time": "2018-03-27T11:16:29.295466Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T11:17:24.286556Z",
     "start_time": "2018-03-27T11:17:24.278538Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.zeros((3, 4))\n",
    "a.dtype == np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `numpy...` $\\to$ `tensorflow`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T11:22:58.533073Z",
     "start_time": "2018-03-27T11:22:58.525112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const:0' shape=(3,) dtype=int32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor([3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T11:23:28.284075Z",
     "start_time": "2018-03-27T11:23:28.278104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_1:0' shape=(4,) dtype=int32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(np.array([3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T11:23:38.413568Z",
     "start_time": "2018-03-27T11:23:38.406568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros_2:0' shape=(3, 4) dtype=float32>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.convert_to_tensor(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 求导\n",
    "\n",
    "## [梯度计算：tf.gradients](https://www.w3cschool.cn/tensorflow_python/tensorflow_python-kbev2ezc.html)\n",
    "`ys` 和 `xs` 是一个张量或一个张量的列表。`grad_ys` 是一个张量列表，持有由 `ys` 接收的梯度。该列表必须与 `ys` 具有相同长度。\n",
    "\n",
    "要注意的是，`xs`中的`x`必须要与`ys`相关，不相关的话，会报错。 \n",
    "\n",
    "错误的例子：\n",
    "代码中定义了两个变量 `w1`， `w2`， 但`res`只与`w1`相关\n",
    "```py\n",
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable([[1, 2]])\n",
    "w2 = tf.Variable([[3, 4]])\n",
    "\n",
    "res = tf.matmul(w1, [[2], [1]])\n",
    "\n",
    "grads = tf.gradients(res, [w1, w2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    re = sess.run(grads)\n",
    "    print(re)\n",
    "```\n",
    "\n",
    "错误信息 \n",
    "```sh\n",
    "TypeError: Fetch argument None has invalid type \n",
    "```\n",
    "\n",
    "正确的姿势："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T13:46:14.306533Z",
     "start_time": "2018-03-27T13:46:13.545783Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[2, 1]])]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable([[1, 2]])\n",
    "w2 = tf.Variable([[3, 4]])\n",
    "\n",
    "res = tf.matmul(w1, [[2], [1]])\n",
    "\n",
    "grads = tf.gradients(res, [w1]) \n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    re = sess.run(grads)\n",
    "    print(re)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gradients()` 向图形添加操作以输出 $\\frac{\\partial ys}{\\partial xs}$ 。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T14:04:48.483172Z",
     "start_time": "2018-03-27T14:04:48.465133Z"
    }
   },
   "source": [
    "- `ys`：要区分的张量或者张量列表。\n",
    "- `xs`：用于微分的张量或者张量列表。\n",
    "- `grad_ys`：（可选）与 `ys` 具有相同大小的张量或张量列表，并且对 `ys` 中的每个 `y` 计算的梯度。\n",
    "- `name`：用于将所有渐变操作组合在一起的可选名称。默认为 “渐变”。\n",
    "- `colocate_gradients_with_ops`：如果为 True，请尝试使用相应的操作对齐梯度。\n",
    "- `gate_gradients`：如果为True，则在操作返回的梯度周围添加一个元组。这避免了一些竞态条件。 \n",
    "- `aggregation_method`：指定用于组合渐变项的方法。接受的值是在类 `AggregationMethod` 中定义的常量。\n",
    "\n",
    "返回值：\n",
    "该函数返回 `xs` 中每个 x 的 `sum(dy/dx)` 的列表\n",
    "\n",
    "可能引发的异常：\n",
    "```py\n",
    "LookupError：如果 x 和 y 之间的一个操作是没有注册的梯度函数。\n",
    "ValueError：如果参数无效。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`grad_ys` 是与 `ys` 相同长度的张量列表，它包含 `y` 的初始梯度。当 `grad_ys` 是 `None` 时，我们在 `ys` 中为每个 `y` 填入一个 `1` 的形状的张量。用户可以提供自己的初始 `grad_ys`，使用不同的初始梯度为每个 `y` 计算导数 (例如：如果你想为每个 `y` 中的每个值不同地加权梯度)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于`grad_ys`的测试："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T14:13:17.564107Z",
     "start_time": "2018-03-27T14:13:09.189693Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([2., 2., 3.], dtype=float32), array([2., 2., 3.], dtype=float32), array([5., 4., 7.], dtype=float32), array([3., 2., 4.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.get_variable('w1', shape=[3])\n",
    "w2 = tf.get_variable('w2', shape=[3])\n",
    "\n",
    "w3 = tf.get_variable('w3', shape=[3])\n",
    "w4 = tf.get_variable('w4', shape=[3])\n",
    "\n",
    "z1 = w1 + w2 + w3\n",
    "z2 = w3 + w4\n",
    "\n",
    "grads = tf.gradients(\n",
    "    [z1, z2], [w1, w2, w3, w4],\n",
    "    grad_ys=[\n",
    "        tf.convert_to_tensor([2., 2., 3.]),\n",
    "        tf.convert_to_tensor([3., 2., 4.])\n",
    "    ])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(grads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:03:33.263463Z",
     "start_time": "2018-03-28T05:03:33.237463Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = tf.constant([[1., 2.], [3, 4]])\n",
    "y = 2 * w \n",
    "z = y * w\n",
    "f = z + w\n",
    "g = tf.gradients([f, z], [w])\n",
    "type(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:03:34.644598Z",
     "start_time": "2018-03-28T05:03:34.206469Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ True  True]\n",
      " [ True  True]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    acc = tf.equal(g[0], 8 * w + 1)\n",
    "    print(sess.run(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:03:35.556620Z",
     "start_time": "2018-03-28T05:03:35.493600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 9., 17.],\n",
      "       [25., 33.]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:04:42.361915Z",
     "start_time": "2018-03-28T05:04:42.352914Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "def opt(w, lr):\n",
    "    for dw in g:\n",
    "        w -= lr * dw\n",
    "    return w\n",
    "\n",
    "w = opt(w, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:04:52.481107Z",
     "start_time": "2018-03-28T05:04:52.056910Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.82000005 1.6600001 ]\n",
      " [2.5        3.3400002 ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.stop_gradient` 阻挡节点 `BP` 的梯度\n",
    "\n",
    "使用`stop_gradient`函数，其输出值与输入相同，但不会参与反向传播中的梯度计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T11:40:08.642848Z",
     "start_time": "2018-03-27T11:40:08.618888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, <tf.Tensor 'gradients_3/Mul_1_grad/Mul_1:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(2.0)\n",
    "w2 = tf.Variable(2.0)\n",
    "\n",
    "a = tf.multiply(w1, 3.0)\n",
    "a_stoped = tf.stop_gradient(a)\n",
    "\n",
    "# b=w1*3.0*w2\n",
    "b = tf.multiply(a_stoped, w2)\n",
    "gradients = tf.gradients(b, xs=[w1, w2])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可见，一个节点被 `stop` 之后，这个节点上的梯度，就无法再向前 `BP` 了。由于 `w1` 变量的梯度只能来自 `a` 节点，所以，计算梯度返回的是 `None`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:08:11.893799Z",
     "start_time": "2018-03-28T05:08:11.799824Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "a = tf.Variable(1.0)\n",
    "b = tf.Variable(1.0)\n",
    "\n",
    "c = tf.add(a, b)\n",
    "\n",
    "c_stoped = tf.stop_gradient(c)\n",
    "\n",
    "d = tf.add(a, b)\n",
    "\n",
    "e = tf.add(c_stoped, d)\n",
    "\n",
    "gradients = tf.gradients(e, xs=[a, b])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然 `c` 节点被 stop 了，但是 `a`，`b` 还有从 `d` 传回的梯度，所以还是可以输出梯度值的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:10:33.795228Z",
     "start_time": "2018-03-28T05:10:33.757265Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-b472c8fd0324>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 这里会报错，因为 gradients[0] 是 None\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;31m#其它地方都会运行正常，无论是梯度的计算还是变量的更新。总觉着tensorflow这么设计有点不好，\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'name'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "w1 = tf.Variable(2.0)\n",
    "w2 = tf.Variable(2.0)\n",
    "a = tf.multiply(w1, 3.0)\n",
    "a_stoped = tf.stop_gradient(a)\n",
    "\n",
    "# b=w1*3.0*w2\n",
    "b = tf.multiply(a_stoped, w2)\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(0.1)\n",
    "\n",
    "gradients = tf.gradients(b, xs=tf.trainable_variables())\n",
    "\n",
    "tf.summary.histogram(gradients[0].name, gradients[0])  # 这里会报错，因为 gradients[0] 是 None\n",
    "#其它地方都会运行正常，无论是梯度的计算还是变量的更新。总觉着tensorflow这么设计有点不好，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:10:43.045308Z",
     "start_time": "2018-03-28T05:10:42.587232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, None, None, None, None, None, None, None, <tf.Tensor 'gradients_29/Mul_1_grad/Mul_1:0' shape=() dtype=float32>]\n",
      "None\n",
      "[2.0, 1.4]\n"
     ]
    }
   ],
   "source": [
    "#不如改成流过去的梯度为0\n",
    "train_op = opt.apply_gradients(zip(gradients, tf.trainable_variables()))\n",
    "\n",
    "print(gradients)\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    print(sess.run(train_op))\n",
    "    print(sess.run([w1, w2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高阶导数\n",
    "tensorflow 求**高阶导数**可以使用 `tf.gradients` 来实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T05:11:23.968717Z",
     "start_time": "2018-03-28T05:11:23.426309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"gradients_30/Pow_grad/Reshape:0\", shape=(), dtype=float32, device=/device:CPU:0)\n",
      "[<tf.Tensor 'gradients_32/gradients_31/gradients_30/Pow_grad/Pow_grad/Pow_grad/Reshape:0' shape=() dtype=float32>]\n",
      "[0.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    a = tf.constant(1.)\n",
    "    b = tf.pow(a, 2)\n",
    "    grad = tf.gradients(ys=b, xs=a)  # 一阶导\n",
    "    print(grad[0])\n",
    "    grad_2 = tf.gradients(ys=grad[0], xs=a)  # 二阶导\n",
    "    grad_3 = tf.gradients(ys=grad_2[0], xs=a)  # 三阶导\n",
    "    print(grad_3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(grad_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: 有些 `op`，`tf` 没有实现其高阶导的计算，例如 `tf.add` …, 如果计算了一个没有实现 高阶导的 `op` 的高阶导， `gradients` 会返回 `None`。\n",
    "\n",
    "## `compute_gradients` 计算导数\n",
    "\n",
    "```py\n",
    "# Create an optimizer.optimizer必须和variable在一个设备上声明\n",
    "opt = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "\n",
    "# Compute the gradients for a list of variables.\n",
    "grads_and_vars = opt.compute_gradients(loss, <list of variables>)\n",
    "\n",
    "# grads_and_vars is a list of tuples (gradient, variable).  Do whatever you\n",
    "# need to the 'gradient' part, for example cap them, etc.\n",
    "capped_grads_and_vars = [(MyCapper(gv[0]), gv[1]) for gv in grads_and_vars]\n",
    "\n",
    "# Ask the optimizer to apply the capped gradients.\n",
    "opt.apply_gradients(capped_grads_and_vars)\n",
    "```\n",
    "或者\n",
    "\n",
    "```py\n",
    "#return a list of trainable variable in you model\n",
    "params = tf.trainable_variables()\n",
    "\n",
    "#create an optimizer\n",
    "opt = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "\n",
    "#compute gradients for params\n",
    "gradients = tf.gradients(loss, params)\n",
    "\n",
    "#process gradients\n",
    "clipped_gradients, norm = tf.clip_by_global_norm(gradients,max_gradient_norm)\n",
    "\n",
    "train_op = opt.apply_gradients(zip(clipped_gradients, params))\n",
    "```\n",
    "\n",
    "这时, `sess.run(train_op)` 就可以进行训练了。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.clip_by_norm` \n",
    "\n",
    "[梯度爆炸的解决办法：clip gradient](https://blog.csdn.net/u010814042/article/details/76154391)\n",
    "\n",
    "对梯度进行裁剪，通过控制梯度的最大范式，防止梯度爆炸的问题，是一种比较常用的梯度规约的方式。\n",
    "```py\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, beta1=0.5)\n",
    "grads = optimizer.compute_gradients(cost)\n",
    "for i, (g, v) in enumerate(grads):\n",
    "    if g is not None:\n",
    "        grads[i] = (tf.clip_by_norm(g, 5), v)  # clip gradients\n",
    "train_op = optimizer.apply_gradients(grads)\n",
    "```\n",
    "\n",
    "通过源码可以清晰的明白其作用在于将传入的梯度张量`t`的 L2 范数进行了上限约束，约束值即为 `clip_norm`，如果`t`的 L2 范数超过了 `clip_norm`，则变换为`t * clip_norm / l2norm(t)`，如此一来，变换后的`t`的 L2 范数便小于等于`clip_norm`了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T12:17:02.884707Z",
     "start_time": "2018-03-27T12:17:02.487670Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 2, 0, 2, 3, 0, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "t = np.random.randint(low=0, high=7, size=10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T12:17:42.534832Z",
     "start_time": "2018-03-27T12:17:42.224834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.48074069840786"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2norm4t = np.linalg.norm(t) # 计算 L2 范数\n",
    "l2norm4t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T12:18:14.786223Z",
     "start_time": "2018-03-27T12:18:14.653251Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 2.1602469 , 0.        ,\n",
       "       2.1602469 , 3.24037035, 0.        , 3.24037035, 4.3204938 ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机数规约\n",
    "clip_norm = 7\n",
    "transformed_t = t * clip_norm / l2norm4t\n",
    "transformed_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T12:18:46.505011Z",
     "start_time": "2018-03-27T12:18:46.379970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.999999999999999"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 验证\n",
    "np.linalg.norm(transformed_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `tf.clip_by_value(A, min, max)`\n",
    "\n",
    "输入一个张量`A`，把`A`中的每一个元素的值都压缩在`min`和`max`之间。小于`min`的让它等于`min`，大于`max`的元素的值等于`max`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T12:21:07.853349Z",
     "start_time": "2018-03-27T12:21:06.873381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 2 4]\n",
      " [3 4 5 5]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[1, 1, 2, 4], [3, 4, 8, 5]])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.clip_by_value(A, 2, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tensorflow的梯度异步更新](https://blog.csdn.net/supe_king/article/details/78017429)\n",
    "## [Tensorflow一些常用基本概念与函数（4）](https://blog.csdn.net/lenbow/article/details/52218551)\n",
    "## [利用 tf.gradients 在 TensorFlow 中实现梯度下降](https://segmentfault.com/a/1190000012531967)\n",
    "## [『TensorFlow』梯度优化相关 ](http://www.cnblogs.com/hellcat/p/7435977.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `tf.train`（优化算法）\n",
    "\n",
    "**`tf` 下以大写字母开头的含义为名词的一般表示一个类（`class`）**。\n",
    "\n",
    "## 优化器（optimizer）\n",
    "优化器的基类（Optimizer base class）主要实现了两个接口，一是计算损失函数的梯度，二是将梯度作用于变量。\n",
    "```py\n",
    "tf.train.Optimizer\n",
    "tf.train.GradientDescentOptimizer\n",
    "tf.train.AdadeltaOpzimizer \n",
    "tf.train.AdagradDAOptimizer\n",
    "tf.train.MomentumOptimizer\n",
    "tf.train.AdamOptimizer\n",
    "tf.train.FtrlOptimizer\n",
    "tf.train.ProximalGradientDescentOptimizer\n",
    "tf.train.ProximalAdagradOptimizer\n",
    "tf.train.RMSPropOptimizer\n",
    "```\n",
    "\n",
    "## 梯度计算\n",
    "\n",
    "TensorFlow 同时也提供了给定 TensorFlow 计算图（computation graph）的导数。优化器类（optimizer classes）会自动计算 computation graph 的导数，但用户自定义优化器时，可以使用如下低级别的函数：\n",
    "```py\n",
    "tf.gradients\n",
    "tf.AggregationMethod\n",
    "tf.stop_gradient\n",
    "tf.hessians\n",
    "```\n",
    "\n",
    "## 学习率衰减（decaying the learning rate）\n",
    "`tf.train.exponential_decay`\n",
    "实现的是如下的操作:\n",
    "$$decayedlr = lr \\times decayrate^{\\frac{globalstep}{decaysteps}}$$\n",
    "\n",
    "```py\n",
    "lr = tf.train.exponential_decay(0.1, global_step, 100, .96, staircase=True)\n",
    "```\n",
    "\n",
    "还有其他的\n",
    "```py\n",
    "tf.train.inverse_time_decay\n",
    "tf.train.natural_exp_decay\n",
    "tf.train.piecewise_constant\n",
    "tf.train.polynomial_decay\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [权值更新](https://blog.csdn.net/GH234505/article/details/54976696)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [分布式Tensorflow的梯度累积与异步更新](https://zhuanlan.zhihu.com/p/23060519)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow 如何自由处理梯度\n",
    "\n",
    "一个优化器：`optm = tf.train.AdamOptimizer(learning_rate).minimize(loss) `\n",
    " `minimize` 可看作 `compute_gradients` 和 `apply_gradients` 二者之和，即计算和更新梯度;另一种更新方式就是先计算梯度，再更新我们需要更新的变量。\n",
    " \n",
    "如下，第一种方式，一步计算：\n",
    "```py\n",
    "t_vars = tf.trainable_variables() #获取所有变量名  \n",
    "G_vars=[var for var in t_vars if 'generator' in var.name] #获取需要的变量名  \n",
    "g_optm = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(g_loss,var_list=G_vars) \n",
    "```\n",
    "\n",
    "第二种方式，分步计算：\n",
    "```py\n",
    "t_vars = tf.trainable_variables()  \n",
    "G_vars=[var for var in t_vars if 'generator' in var.name]  \n",
    "gradient_all =tf.train.GradientDescentOptimizer(0.01).compute_gradients(loss,var_list=G_vars) #对应变量名的梯度计算,这是第一步  \n",
    "optm = tf.train.GradientDescentOptimizer(0.01).apply_gradients(gradient_all) #更新计算出来的梯度，这是第二步  \n",
    "```\n",
    "另外，还有两个函数，不常用到，了解一下即可：\n",
    "`tf.gradients(ys, xs, grad_ys=None, name=’gradients’, colocate_gradients_with_ops=False, gate_gradients=False, aggregation_method=None)` \n",
    "该函数计算`ys`在`xs`方向上的梯度，需要注意与`train.compute_gradients`所不同的地方是，该函数返回一组`dy/dx`的列表，而不是梯度-权值对；\n",
    "`tf.stop_gradient(input, name=None)`该函数告知整个 graph 图中，对 input 不进行梯度计算，将其伪装成一个 constant 常量。\n",
    "\n",
    "下面还有一些其他的技巧：\n",
    "- `gradient_all = optimizer.compute_gradients(loss)` 计算全部 gradient \n",
    "- `grads_vars = [v for (g,v) in gradient_all if g is not None]`  得到可进行梯度计算的变量\n",
    "- `gradient = optimizer.compute_gradients(loss, grads_vars)` 得到所需梯度\n",
    "- `grads_holder = [(tf.placeholder(tf.float32, shape=g.get_shape()), v) for (g,v) in gradient]` 生成holder \n",
    "- `train_op = optimizer.apply_gradients(grads_holder)` 继续进行 BP 算法\n",
    "- `gradient_result = sess.run(gradient, feed_dict={x:x_i,y_:y_real})`生成结果，计算`loss`与`gradient`\n",
    "\n",
    "```py\n",
    "grads_dict={} \n",
    "for i in range(len(gradient_result)): \n",
    "  k = grads_holder[i][0] # 取出holder，用于后面的feed_dict \n",
    "  grads_dict[k] = DealTheGradientFunction(gradient_result[i][0]) # 自由处理梯度\n",
    "```\n",
    "继续更新权值：`_ = sess.run(train_op,feed_dict=grads_dict)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips\n",
    "## glob\n",
    "在linux下 `glob` 得到的列表是乱序的，需要用sort重新排序。windows 下 `glob` 的到的列表顺序和文件夹显示的顺序一致。由于这一错误导致我在Linux 下训练的模型在 windows 下测试，准确率为`0`的bug。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T13:16:28.161100Z",
     "start_time": "2018-03-27T13:16:28.157106Z"
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-27T13:16:38.075099Z",
     "start_time": "2018-03-27T13:16:36.036131Z"
    }
   },
   "source": [
    "## `tf.shape` 和 `get_shape` 的区别\n",
    "- 相同点：都可以得到tensor `a`的尺寸\n",
    "- 不同点：`tf.shape(a)` 中 `a` 数据的类型可以是 `tensor`, `list`, `array` \n",
    "  - `a.get_shape()` 中 `a` 的数据类型只能是 `tensor`,且返回的是一个元组（`tuple`）\n",
    "  \n",
    "另外，`a.get_shape()` 得到的`tuple`可以利用 `a.get_shape().as_list`  转成列表，从而对维度进行调用。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 内存的使用\n",
    "```py\n",
    "with tf.device('/gpu:0'):  \n",
    "```\n",
    "可以使用这一条代码指定某段程序在某一个 GPU 上运算，但仍然会默认占用所有 GPU 资源。不过不和其他人公用 GPU 时也不会有影响，下面介绍两种限定GPU占用的方法：\n",
    "- (1)在tensorflow中定义`session`时作如下设置，该设置会启用最少的 GPU 显存来运行程序：\n",
    "```py\n",
    "config = tf.ConfigProto()   \n",
    "config.gpu_options.allow_growth = True   \n",
    "session = tf.Session(config=config)\n",
    "```\n",
    "- (2)在tensorflow中定义`session`时作如下设置，该设置会强制程序只占用指定比例的 GPU 显存\n",
    "```py\n",
    "config = tf.ConfigProto()   \n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4 # 占用GPU40%的显存   \n",
    "session = tf.Session(config=config)  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实例\n",
    "\n",
    "## 线性模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T06:51:54.124968Z",
     "start_time": "2018-03-29T06:51:54.118967Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('E:/xinlib')\n",
    "import xin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:09:45.845424Z",
     "start_time": "2018-03-29T07:09:45.818425Z"
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "\n",
    "true_w = [2, -3.4]\n",
    "true_b = 4.2\n",
    "\n",
    "X = tf.random_normal(shape=(num_examples, num_inputs))\n",
    "y = true_w[0] * X[:, 0] + true_w[1] * X[:, 1] + true_b\n",
    "y += .01 * tf.random_normal(shape=y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T06:52:00.797486Z",
     "start_time": "2018-03-29T06:51:56.653490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2047b7f0a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x, y = sess.run([X[:, 1], y])\n",
    "    \n",
    "%pylab inline \n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-28T10:46:47.410500Z",
     "start_time": "2018-03-28T10:46:47.405460Z"
    }
   },
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T06:58:15.241391Z",
     "start_time": "2018-03-29T06:58:15.238361Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `tf.data`\n",
    "\n",
    "[Introduction to TensorFlow Datasets and Estimators ](https://developers.googleblog.com/2017/09/introducing-tensorflow-datasets.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `tf.feature_column`\n",
    "[Introducing TensorFlow Feature Columns](https://developers.googleblog.com/2017/11/introducing-tensorflow-feature-columns.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [实践指南！16位资深行业者教你如何学习使用TensorFlow](https://yq.aliyun.com/articles/71257?spm=a2c4e.11153940.blogcont159607.7.3631c0d0PvdaZt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:19:17.392853Z",
     "start_time": "2018-03-29T07:19:17.389847Z"
    }
   },
   "source": [
    "# [一步步带你探究如何高效使用TensorFlow](https://yq.aliyun.com/articles/159607)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:20:20.587780Z",
     "start_time": "2018-03-29T07:20:20.575776Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.03331374   6.19707923  -2.65490643  -3.11765891  -3.00808424\n",
      "    2.33188916  -0.28865182   0.05087656  -1.34591431  -0.54639253]\n",
      " [  3.67046851  -2.91739165   4.75408801   2.09665533  -5.55064586\n",
      "   -0.46559925   2.82975126  -2.98270113  -0.02802994  -0.93889597]\n",
      " [ -1.78899577   1.920233    -0.41724299  -2.20148806   1.00424694\n",
      "    3.85985832  -0.76609938  -0.65608963   6.31061359  -3.52004825]\n",
      " [  0.31710265   1.22672474   0.25260203  -3.24767086   2.36133336\n",
      "    3.01376792  -2.66408039  -0.31694837  -2.25025004   3.43554427]\n",
      " [  0.61614322  -0.45212473  -1.36364379  -0.44071573   2.0418642\n",
      "    3.51081078  -1.40006173   3.52076313   4.9593532    4.88758445]\n",
      " [ -0.78130895   0.65931508  -0.53749482   0.4980627   -1.10368293\n",
      "   -4.50019785   2.05422741   2.22937077   0.45502323  -2.75807115]\n",
      " [ -5.24531503   0.82081194   1.5217025   -2.21103868  -5.20085584\n",
      "    4.10433908  -1.85932076  -0.49930007   1.52608001  -4.52715066]\n",
      " [ -1.67055655  -1.13645355   0.87097301  -3.21453496   1.40820659\n",
      "   -1.47861957   1.66244674   0.94610872  -7.23082102   2.35907313]\n",
      " [  0.57940734   3.46020879  -3.11309051   1.22238941   2.55590471\n",
      "    0.64525472  -3.31467696  -1.81144282   3.808075    -2.4140626 ]\n",
      " [ -0.93342118  -5.64140173   2.78495538   3.58275738   4.58406517\n",
      "  -10.66439619  -7.20183682  -2.05447856  -4.6499406    0.79319563]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.random.normal(size=[10, 10])\n",
    "y = np.random.normal(size=[10, 10])\n",
    "z = np.dot(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:20:52.566689Z",
     "start_time": "2018-03-29T07:20:51.640317Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-6.0421467  -4.002712   -3.4028344   5.4274063  -3.2356334  -1.8574154\n",
      "  -0.28259626 -4.578471    0.7213292   3.9324884 ]\n",
      " [-0.47098017  2.2730732   6.550978    2.4557724  -0.45082462 -0.22762877\n",
      "  -5.4430184   1.5002248   4.0452495   7.0937047 ]\n",
      " [-1.0261753   1.729397    1.9933732  -4.360579    1.6377666   4.4436703\n",
      "  -0.13812351  6.3661013  -0.23438215 -0.2771334 ]\n",
      " [ 4.910007   -3.0467596  -4.930425   -1.1172944   0.03339058 -4.2460065\n",
      "  -1.9423164  -2.6526754  -1.4606994  -1.095494  ]\n",
      " [ 1.3435711   3.993326    1.5301259  -1.1121674   1.9628985   1.8056077\n",
      "   2.4359083   2.3335717  -1.0083514  -1.0688686 ]\n",
      " [ 5.6436744  -3.4744835  -4.8716187   1.5645031  -0.2647297  -6.4770794\n",
      "  -4.1336164  -4.3394995  -1.2156465  -1.0004427 ]\n",
      " [ 2.299832    1.4956679   4.046055   -0.40779734  5.0517254   4.0086474\n",
      "   1.670546    0.6349054   2.3316076  -1.6516174 ]\n",
      " [-0.94313014  0.75890946 -0.24313027  0.4651425  -0.63462377 -0.32604343\n",
      "  -3.5050843   2.5974834   0.9161282   4.0798054 ]\n",
      " [ 0.3876887   2.3671348   0.53561604 -3.0781217   0.18687665  2.6030815\n",
      "   1.6102548   0.11304009 -0.9085276  -4.005033  ]\n",
      " [-0.8671427   1.3518863  -1.0807189   2.2388906  -1.3088808  -2.129134\n",
      "  -0.5086459   1.8665991   0.8610807   1.8279966 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.random_normal([10, 10])\n",
    "y = tf.random_normal([10, 10])\n",
    "z = tf.matmul(x, y)\n",
    "sess = tf.Session()\n",
    "z_val = sess.run(z)\n",
    "print(z_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:22:01.556081Z",
     "start_time": "2018-03-29T07:21:58.944709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3143759.0\n",
      "3740112.0\n",
      "3608657.2\n",
      "2515516.2\n",
      "3038907.2\n",
      "2588791.2\n",
      "3119756.2\n",
      "2549852.5\n",
      "2220376.8\n",
      "2708472.8\n",
      "2576062.2\n",
      "2492518.8\n",
      "2039833.5\n",
      "2259819.8\n",
      "1931321.6\n",
      "1719102.9\n",
      "1973012.9\n",
      "1594744.6\n",
      "2184101.2\n",
      "1594456.0\n",
      "1207074.1\n",
      "1303249.9\n",
      "1355927.6\n",
      "1094771.4\n",
      "1321905.6\n",
      "866927.75\n",
      "1350942.4\n",
      "864273.25\n",
      "1183633.6\n",
      "1047666.4\n",
      "934974.0\n",
      "930504.25\n",
      "928699.5\n",
      "655231.7\n",
      "596410.75\n",
      "721939.3\n",
      "491044.12\n",
      "450454.44\n",
      "555685.44\n",
      "406265.7\n",
      "538209.75\n",
      "560216.94\n",
      "473007.94\n",
      "404060.7\n",
      "409225.88\n",
      "376299.88\n",
      "329518.12\n",
      "306558.75\n",
      "325387.84\n",
      "270446.4\n",
      "223664.11\n",
      "222827.56\n",
      "217542.27\n",
      "216481.9\n",
      "209596.64\n",
      "173116.69\n",
      "155292.44\n",
      "137046.23\n",
      "115506.29\n",
      "104236.29\n",
      "99822.266\n",
      "91211.25\n",
      "122778.27\n",
      "74970.766\n",
      "59496.613\n",
      "64921.918\n",
      "59790.38\n",
      "51396.11\n",
      "53644.49\n",
      "46372.645\n",
      "45027.742\n",
      "36598.766\n",
      "31598.027\n",
      "32428.33\n",
      "28968.773\n",
      "21590.38\n",
      "23217.35\n",
      "19578.488\n",
      "19203.758\n",
      "12056.286\n",
      "13305.461\n",
      "12619.753\n",
      "9759.518\n",
      "9880.029\n",
      "8764.966\n",
      "6232.3887\n",
      "6538.0015\n",
      "4720.905\n",
      "4752.2524\n",
      "3011.5452\n",
      "3251.0444\n",
      "4056.34\n",
      "2465.4026\n",
      "2212.9578\n",
      "1682.897\n",
      "1252.2856\n",
      "1432.9865\n",
      "1072.9551\n",
      "684.302\n",
      "635.0142\n",
      "603.1076\n",
      "485.29834\n",
      "445.19135\n",
      "315.68634\n",
      "330.56958\n",
      "219.82594\n",
      "205.91937\n",
      "201.40958\n",
      "158.2918\n",
      "154.6335\n",
      "131.93967\n",
      "151.94283\n",
      "129.9133\n",
      "143.06535\n",
      "133.70839\n",
      "150.42194\n",
      "133.06966\n",
      "140.27986\n",
      "146.76003\n",
      "154.80504\n",
      "153.47163\n",
      "163.27853\n",
      "142.69632\n",
      "159.26491\n",
      "184.46184\n",
      "149.33748\n",
      "135.99747\n",
      "150.97058\n",
      "167.74707\n",
      "152.93448\n",
      "160.71208\n",
      "178.91978\n",
      "169.39127\n",
      "154.47786\n",
      "149.4076\n",
      "169.74634\n",
      "161.46925\n",
      "156.27612\n",
      "148.19849\n",
      "135.99786\n",
      "140.51425\n",
      "168.91849\n",
      "139.97339\n",
      "150.66397\n",
      "135.82533\n",
      "125.14557\n",
      "130.45232\n",
      "145.55757\n",
      "131.69785\n",
      "138.21992\n",
      "159.7013\n",
      "143.8443\n",
      "136.20958\n",
      "123.98153\n",
      "139.89856\n",
      "119.79665\n",
      "118.77604\n",
      "132.8598\n",
      "132.91185\n",
      "132.15616\n",
      "130.13402\n",
      "131.45811\n",
      "134.51189\n",
      "136.08545\n",
      "124.966896\n",
      "141.7807\n",
      "129.11781\n",
      "127.834236\n",
      "124.60428\n",
      "136.50978\n",
      "122.27625\n",
      "133.6992\n",
      "125.31959\n",
      "116.19995\n",
      "127.10294\n",
      "130.60501\n",
      "126.516\n",
      "123.51197\n",
      "114.85284\n",
      "133.11171\n",
      "133.01935\n",
      "127.702065\n",
      "100.82474\n",
      "131.22212\n",
      "113.443474\n",
      "114.95588\n",
      "139.2274\n",
      "133.52448\n",
      "141.20474\n",
      "124.28249\n",
      "134.49586\n",
      "136.26796\n",
      "136.15817\n",
      "137.61119\n",
      "121.46802\n",
      "133.10107\n",
      "128.01118\n",
      "121.48394\n",
      "123.590355\n",
      "125.429726\n",
      "124.03452\n",
      "122.72691\n",
      "118.16073\n",
      "118.7469\n",
      "130.65004\n",
      "113.49897\n",
      "142.45004\n",
      "136.608\n",
      "129.45999\n",
      "117.15058\n",
      "138.41714\n",
      "121.45383\n",
      "128.86444\n",
      "118.79807\n",
      "119.07259\n",
      "111.57645\n",
      "114.795815\n",
      "123.38791\n",
      "119.39637\n",
      "129.20741\n",
      "125.28995\n",
      "107.178444\n",
      "128.59084\n",
      "127.28261\n",
      "116.691574\n",
      "137.71301\n",
      "143.62994\n",
      "119.043045\n",
      "118.727936\n",
      "116.703316\n",
      "124.11827\n",
      "109.317345\n",
      "119.52061\n",
      "123.37272\n",
      "114.97719\n",
      "113.07822\n",
      "124.727356\n",
      "98.634445\n",
      "120.832954\n",
      "105.8288\n",
      "100.081604\n",
      "111.84633\n",
      "108.280235\n",
      "101.52269\n",
      "113.352905\n",
      "127.14157\n",
      "116.34522\n",
      "124.09184\n",
      "109.05017\n",
      "106.475296\n",
      "106.64969\n",
      "108.60813\n",
      "109.47022\n",
      "104.46795\n",
      "104.38321\n",
      "116.04019\n",
      "90.98247\n",
      "121.206055\n",
      "100.21532\n",
      "111.22289\n",
      "112.00435\n",
      "130.13873\n",
      "123.50309\n",
      "106.330635\n",
      "106.072296\n",
      "128.02707\n",
      "110.79767\n",
      "103.748146\n",
      "109.90642\n",
      "104.472534\n",
      "106.17923\n",
      "100.179855\n",
      "110.98097\n",
      "101.18715\n",
      "104.78481\n",
      "107.13754\n",
      "127.531044\n",
      "116.56591\n",
      "101.26318\n",
      "90.21737\n",
      "113.62617\n",
      "117.63442\n",
      "100.89206\n",
      "106.620544\n",
      "110.22782\n",
      "99.58976\n",
      "99.6924\n",
      "115.620865\n",
      "116.41295\n",
      "103.026085\n",
      "106.19018\n",
      "102.616165\n",
      "100.80569\n",
      "110.01303\n",
      "101.42578\n",
      "104.54095\n",
      "108.07656\n",
      "89.798195\n",
      "123.483185\n",
      "93.343475\n",
      "101.63813\n",
      "106.34564\n",
      "103.471794\n",
      "111.96391\n",
      "104.023834\n",
      "105.847244\n",
      "101.9863\n",
      "101.95134\n",
      "105.0985\n",
      "104.71505\n",
      "92.08764\n",
      "102.95099\n",
      "83.5665\n",
      "96.39081\n",
      "106.57035\n",
      "99.16635\n",
      "93.98456\n",
      "86.2499\n",
      "97.362305\n",
      "97.0128\n",
      "109.756096\n",
      "102.85564\n",
      "96.767685\n",
      "103.02125\n",
      "90.221146\n",
      "100.127365\n",
      "84.91011\n",
      "94.993706\n",
      "119.54823\n",
      "94.78971\n",
      "104.79511\n",
      "102.77023\n",
      "101.375946\n",
      "85.629616\n",
      "103.41362\n",
      "87.61702\n",
      "94.96129\n",
      "91.52772\n",
      "93.257935\n",
      "93.68035\n",
      "95.920685\n",
      "100.19334\n",
      "90.687355\n",
      "106.55385\n",
      "101.93226\n",
      "83.147675\n",
      "99.654434\n",
      "88.90359\n",
      "89.43241\n",
      "93.12452\n",
      "86.825516\n",
      "106.845146\n",
      "92.86131\n",
      "101.56965\n",
      "92.96841\n",
      "83.89387\n",
      "95.379944\n",
      "75.310905\n",
      "88.15885\n",
      "97.30815\n",
      "92.550446\n",
      "103.75135\n",
      "95.99849\n",
      "100.40531\n",
      "85.68289\n",
      "96.2802\n",
      "94.34736\n",
      "84.85131\n",
      "95.67214\n",
      "92.93688\n",
      "83.40181\n",
      "98.31974\n",
      "95.67043\n",
      "88.63731\n",
      "91.10625\n",
      "77.824745\n",
      "93.7584\n",
      "88.58704\n",
      "92.27624\n",
      "88.04158\n",
      "90.2904\n",
      "87.24387\n",
      "96.916214\n",
      "88.093834\n",
      "89.458595\n",
      "86.92388\n",
      "95.1823\n",
      "85.88242\n",
      "74.88752\n",
      "80.92004\n",
      "75.20431\n",
      "87.852356\n",
      "92.21003\n",
      "79.465454\n",
      "96.49843\n",
      "78.42239\n",
      "83.62671\n",
      "73.98807\n",
      "81.97285\n",
      "89.67719\n",
      "93.53102\n",
      "89.541695\n",
      "84.24944\n",
      "93.16867\n",
      "93.85415\n",
      "85.68385\n",
      "85.95711\n",
      "87.73378\n",
      "89.90534\n",
      "80.68419\n",
      "68.764404\n",
      "84.953545\n",
      "75.51803\n",
      "86.92518\n",
      "81.784615\n",
      "90.05058\n",
      "77.82309\n",
      "84.402626\n",
      "84.85077\n",
      "78.23151\n",
      "82.92689\n",
      "73.740875\n",
      "80.50229\n",
      "92.65926\n",
      "73.327965\n",
      "85.201294\n",
      "80.95573\n",
      "90.31806\n",
      "84.50006\n",
      "80.69793\n",
      "70.4695\n",
      "81.61897\n",
      "77.784225\n",
      "87.39568\n",
      "78.992\n",
      "89.20975\n",
      "90.94223\n",
      "83.382935\n",
      "86.22717\n",
      "93.4301\n",
      "82.41881\n",
      "74.73942\n",
      "80.5665\n",
      "83.83192\n",
      "80.12262\n",
      "83.15933\n",
      "88.212296\n",
      "83.664505\n",
      "72.11124\n",
      "75.54881\n",
      "77.240654\n",
      "83.09386\n",
      "67.73957\n",
      "78.29381\n",
      "74.860214\n",
      "70.41541\n",
      "74.81768\n",
      "70.506546\n",
      "74.04173\n",
      "72.60618\n",
      "70.52904\n",
      "82.10774\n",
      "72.4078\n",
      "70.68944\n",
      "85.84634\n",
      "61.349632\n",
      "77.29709\n",
      "70.67104\n",
      "71.522995\n",
      "66.99266\n",
      "84.24667\n",
      "74.918205\n",
      "79.74654\n",
      "79.20303\n",
      "69.142685\n",
      "64.45715\n",
      "76.30748\n",
      "69.93409\n",
      "64.552025\n",
      "74.29149\n",
      "75.70067\n",
      "77.55611\n",
      "75.9271\n",
      "65.60687\n",
      "74.62061\n",
      "64.814095\n",
      "72.411415\n",
      "72.681526\n",
      "79.34691\n",
      "70.48071\n",
      "70.9765\n",
      "66.021965\n",
      "60.905018\n",
      "67.68984\n",
      "70.51973\n",
      "69.598785\n",
      "62.666924\n",
      "72.284355\n",
      "75.50471\n",
      "67.828735\n",
      "69.88342\n",
      "64.67238\n",
      "69.29582\n",
      "64.15575\n",
      "66.48829\n",
      "64.58792\n",
      "67.54342\n",
      "71.54853\n",
      "53.942924\n",
      "62.655796\n",
      "59.11277\n",
      "63.567905\n",
      "68.03051\n",
      "71.70531\n",
      "61.46787\n",
      "63.27477\n",
      "68.478165\n",
      "59.902077\n",
      "61.393112\n",
      "58.698784\n",
      "64.78165\n",
      "64.2381\n",
      "68.47971\n",
      "62.843693\n",
      "52.303925\n",
      "62.446175\n",
      "77.75956\n",
      "74.7267\n",
      "69.21845\n",
      "69.22929\n",
      "60.074013\n",
      "62.907093\n",
      "55.66774\n",
      "56.403137\n",
      "59.523457\n",
      "62.248127\n",
      "51.7264\n",
      "55.574154\n",
      "63.53168\n",
      "60.13211\n",
      "55.94115\n",
      "64.70302\n",
      "59.23907\n",
      "60.637913\n",
      "67.61286\n",
      "50.722683\n",
      "53.67948\n",
      "60.76756\n",
      "61.5518\n",
      "65.65681\n",
      "58.881336\n",
      "60.314632\n",
      "58.559803\n",
      "65.058685\n",
      "60.86512\n",
      "61.009125\n",
      "60.72585\n",
      "56.989487\n",
      "59.62096\n",
      "66.44278\n",
      "61.71343\n",
      "55.775417\n",
      "64.603134\n",
      "62.86034\n",
      "61.912777\n",
      "53.73329\n",
      "65.26491\n",
      "54.67965\n",
      "54.51469\n",
      "57.895412\n",
      "59.667618\n",
      "55.034866\n",
      "51.073063\n",
      "47.477097\n",
      "57.27295\n",
      "53.541702\n",
      "48.628746\n",
      "57.88565\n",
      "51.42128\n",
      "54.02626\n",
      "57.21993\n",
      "60.14425\n",
      "56.861908\n",
      "60.82645\n",
      "47.35897\n",
      "62.32378\n",
      "55.10408\n",
      "52.881638\n",
      "50.644394\n",
      "54.429344\n",
      "51.285057\n",
      "54.635685\n",
      "51.911774\n",
      "51.745594\n",
      "56.958866\n",
      "59.08268\n",
      "52.25336\n",
      "52.112617\n",
      "50.94957\n",
      "48.468483\n",
      "46.31621\n",
      "59.74334\n",
      "53.547565\n",
      "47.997612\n",
      "49.721256\n",
      "58.23021\n",
      "52.306427\n",
      "49.410233\n",
      "47.111816\n",
      "46.1789\n",
      "54.040363\n",
      "51.137783\n",
      "54.79402\n",
      "51.62972\n",
      "53.500893\n",
      "59.518246\n",
      "39.989788\n",
      "51.205547\n",
      "50.563248\n",
      "54.816154\n",
      "48.7526\n",
      "52.6377\n",
      "55.17533\n",
      "44.759804\n",
      "47.668316\n",
      "56.953594\n",
      "52.42502\n",
      "50.41024\n",
      "46.943474\n",
      "53.02843\n",
      "47.869938\n",
      "53.992687\n",
      "49.28928\n",
      "55.97503\n",
      "44.24434\n",
      "47.52752\n",
      "47.504143\n",
      "51.642654\n",
      "53.440636\n",
      "43.569828\n",
      "46.46334\n",
      "48.808475\n",
      "44.862217\n",
      "43.82875\n",
      "48.61046\n",
      "46.287304\n",
      "50.79272\n",
      "43.871887\n",
      "49.308403\n",
      "52.07932\n",
      "52.55434\n",
      "48.160133\n",
      "51.505512\n",
      "51.172264\n",
      "50.0546\n",
      "42.226265\n",
      "48.63257\n",
      "48.437893\n",
      "51.38661\n",
      "46.408577\n",
      "45.145176\n",
      "38.464916\n",
      "49.19055\n",
      "39.866722\n",
      "42.510033\n",
      "37.902634\n",
      "42.057884\n",
      "48.981136\n",
      "40.55849\n",
      "44.81689\n",
      "47.708893\n",
      "46.72598\n",
      "45.563656\n",
      "44.12753\n",
      "39.813606\n",
      "44.842026\n",
      "44.817375\n",
      "40.575344\n",
      "44.152008\n",
      "42.02277\n",
      "46.741055\n",
      "42.859894\n",
      "40.690563\n",
      "44.028595\n",
      "34.68357\n",
      "43.05336\n",
      "34.589264\n",
      "41.577896\n",
      "39.93732\n",
      "38.184097\n",
      "37.721275\n",
      "38.76613\n",
      "41.36672\n",
      "41.50985\n",
      "35.16276\n",
      "40.13937\n",
      "39.250153\n",
      "45.024136\n",
      "35.31596\n",
      "41.29693\n",
      "40.16635\n",
      "38.776752\n",
      "43.408165\n",
      "40.919846\n",
      "40.15715\n",
      "41.751102\n",
      "42.05288\n",
      "38.71465\n",
      "41.323765\n",
      "43.160652\n",
      "46.251827\n",
      "35.764362\n",
      "42.936275\n",
      "36.993637\n",
      "38.412186\n",
      "34.95534\n",
      "35.704906\n",
      "35.925194\n",
      "40.37427\n",
      "40.873936\n",
      "38.47906\n",
      "38.452736\n",
      "41.4777\n",
      "34.56759\n",
      "36.07779\n",
      "39.309933\n",
      "34.86891\n",
      "37.468674\n",
      "38.02534\n",
      "40.570694\n",
      "40.291122\n",
      "38.66474\n",
      "37.43341\n",
      "38.68458\n",
      "37.531723\n",
      "40.86204\n",
      "33.847115\n",
      "31.260363\n",
      "35.021408\n",
      "37.3359\n",
      "33.669224\n",
      "36.513878\n",
      "36.887444\n",
      "33.704136\n",
      "39.347397\n",
      "39.297207\n",
      "32.60334\n",
      "33.54082\n",
      "31.563337\n",
      "36.696293\n",
      "37.736115\n",
      "34.686916\n",
      "36.251354\n",
      "31.5728\n",
      "31.969744\n",
      "38.052814\n",
      "31.126247\n",
      "30.507696\n",
      "32.217636\n",
      "33.0784\n",
      "35.03162\n",
      "33.873875\n",
      "29.328064\n",
      "31.915623\n",
      "32.96169\n",
      "33.402966\n",
      "35.532986\n",
      "34.607212\n",
      "29.110224\n",
      "31.455301\n",
      "31.66526\n",
      "27.609833\n",
      "35.60259\n",
      "32.661816\n",
      "29.696321\n",
      "33.141983\n",
      "28.597546\n",
      "31.305786\n",
      "27.854902\n",
      "31.291443\n",
      "36.341335\n",
      "34.632725\n",
      "34.91814\n",
      "30.863354\n",
      "31.803576\n",
      "32.214825\n",
      "31.873268\n",
      "32.19433\n",
      "31.102089\n",
      "30.021456\n",
      "27.91933\n",
      "27.687593\n",
      "31.655548\n",
      "29.616001\n",
      "31.099773\n",
      "24.928892\n",
      "24.065348\n",
      "31.759811\n",
      "31.37205\n",
      "34.138313\n",
      "28.950945\n",
      "29.574656\n",
      "29.250362\n",
      "27.658625\n",
      "30.502472\n",
      "33.215286\n",
      "27.801702\n",
      "28.092255\n",
      "31.781796\n",
      "30.642727\n",
      "23.242962\n",
      "25.687496\n",
      "33.72679\n",
      "29.582994\n",
      "27.136612\n",
      "25.946272\n",
      "27.602264\n",
      "29.258207\n",
      "28.802563\n",
      "29.024954\n",
      "26.555685\n",
      "28.245182\n",
      "29.495432\n",
      "27.828325\n",
      "28.60463\n",
      "28.087929\n",
      "25.553205\n",
      "28.174953\n",
      "25.129347\n",
      "29.252007\n",
      "27.310806\n",
      "28.94877\n",
      "27.175022\n",
      "28.08493\n",
      "24.763496\n",
      "25.305159\n",
      "29.073353\n",
      "28.824759\n",
      "27.214605\n",
      "27.435444\n",
      "28.222607\n",
      "25.787249\n",
      "27.623116\n",
      "27.286526\n",
      "24.12498\n",
      "26.575424\n",
      "25.435186\n",
      "21.838476\n",
      "26.680202\n",
      "27.283276\n",
      "26.364277\n",
      "23.90853\n",
      "25.936073\n",
      "25.144156\n",
      "25.41097\n",
      "25.853825\n",
      "25.728565\n",
      "25.459066\n",
      "25.2062\n",
      "27.944683\n",
      "24.907412\n",
      "27.006954\n",
      "25.11929\n",
      "21.886047\n",
      "21.938213\n",
      "25.146755\n",
      "23.066814\n",
      "23.218304\n",
      "21.754726\n",
      "24.849503\n",
      "22.399048\n",
      "23.112267\n",
      "25.799124\n",
      "24.422043\n",
      "25.530907\n",
      "22.731018\n",
      "21.510868\n",
      "23.432386\n",
      "23.810291\n",
      "26.35827\n",
      "25.004044\n",
      "22.137205\n",
      "21.540047\n",
      "23.363865\n",
      "24.37419\n",
      "22.751772\n",
      "23.349539\n",
      "22.023567\n",
      "22.23098\n",
      "22.346998\n",
      "20.238434\n",
      "21.949314\n",
      "23.973253\n",
      "22.455938\n",
      "23.042131\n",
      "22.502357\n",
      "21.684498\n",
      "22.780338\n",
      "21.802803\n",
      "21.066402\n",
      "22.526392\n",
      "21.28947\n",
      "23.942696\n",
      "22.431086\n",
      "23.072414\n",
      "22.014967\n",
      "18.503061\n",
      "21.576988\n",
      "23.090622\n",
      "20.43511\n",
      "24.993965\n",
      "22.63439\n",
      "17.897814\n",
      "19.537224\n",
      "19.601562\n",
      "21.7029\n",
      "23.107893\n",
      "18.395737\n",
      "21.85931\n",
      "20.612753\n",
      "19.533543\n",
      "19.187353\n",
      "19.928143\n",
      "20.367992\n",
      "21.683914\n",
      "20.585634\n",
      "20.647545\n",
      "20.32917\n",
      "19.891354\n",
      "16.564068\n",
      "20.492887\n",
      "18.04905\n",
      "19.525496\n",
      "19.469736\n",
      "20.365479\n",
      "21.012156\n",
      "17.530949\n",
      "18.754429\n",
      "16.288597\n",
      "19.40816\n",
      "18.694849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.270063\n",
      "17.713366\n",
      "19.926014\n",
      "18.140945\n",
      "20.88477\n",
      "17.564611\n",
      "16.631016\n",
      "17.42385\n",
      "17.522978\n",
      "19.754852\n",
      "19.021847\n",
      "18.781872\n",
      "15.904143\n",
      "18.549677\n",
      "16.132143\n",
      "17.527224\n",
      "17.073736\n",
      "16.739182\n",
      "14.486741\n",
      "17.275696\n",
      "16.414764\n",
      "17.973736\n",
      "18.638836\n",
      "17.293047\n",
      "15.548361\n",
      "17.09206\n",
      "18.162504\n",
      "18.703545\n",
      "16.383549\n",
      "15.702926\n",
      "15.312151\n",
      "16.297485\n",
      "15.723501\n",
      "17.451061\n",
      "18.196142\n",
      "16.266468\n",
      "17.886166\n",
      "15.444521\n",
      "18.545992\n",
      "14.388419\n",
      "17.83402\n",
      "15.825032\n",
      "17.309952\n",
      "16.084635\n",
      "14.718386\n",
      "17.588358\n",
      "16.438162\n",
      "16.0892\n",
      "14.528255\n",
      "16.732674\n",
      "16.169094\n",
      "13.926801\n",
      "16.269701\n",
      "15.13307\n",
      "15.692302\n",
      "14.934718\n",
      "16.534472\n",
      "14.817079\n",
      "15.817457\n",
      "[array([[4.9875326e+00],\n",
      "       [1.2238083e-03],\n",
      "       [3.7676127e+00]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "w = tf.get_variable(\"w\", shape=[3, 1])\n",
    "f = tf.stack([tf.square(x), x, tf.ones_like(x)], 1)\n",
    "yhat = tf.squeeze(tf.matmul(f, w), 1)\n",
    "loss = tf.nn.l2_loss(yhat - y) + 0.1 * tf.nn.l2_loss(w)\n",
    "train_op = tf.train.AdamOptimizer(0.1).minimize(loss)\n",
    "\n",
    "\n",
    "def generate_data():\n",
    "    x_val = np.random.uniform(-10.0, 10.0, size=100)\n",
    "    y_val = 5 * np.square(x_val) + 3\n",
    "    return x_val, y_val\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for _ in range(1000):\n",
    "    x_val, y_val = generate_data()\n",
    "    _, loss_val = sess.run([train_op, loss], {x: x_val, y: y_val})\n",
    "    print(loss_val)\n",
    "print(sess.run([w]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理解静态形状和动态形状的区别：\n",
    "\n",
    "Tensorflow 中的张量在图形构造期间具有静态的形状属性。例如，我们可以定义一个形状的张量`[None，128]`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:24:26.458623Z",
     "start_time": "2018-03-29T07:24:26.453650Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.placeholder(tf.float32, [None, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:25:04.834051Z",
     "start_time": "2018-03-29T07:25:04.827048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 128]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_shape = a.get_shape().as_list()  # returns [None, 128]\n",
    "static_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了获得张量的动态形状，你可以调用 `tf.shape` op，它将返回一个表示给定形状的张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:25:58.940240Z",
     "start_time": "2018-03-29T07:25:58.934218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Shape_1:0' shape=(2,) dtype=int32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dynamic_shape = tf.shape(a)\n",
    "dynamic_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以使用 `Tensor.set_shape` 方法设置张量的静态形状："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:27:10.150211Z",
     "start_time": "2018-03-29T07:27:10.147228Z"
    }
   },
   "outputs": [],
   "source": [
    "a.set_shape([32, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上使用 `tf.reshape` 操作更为安全："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:27:49.579129Z",
     "start_time": "2018-03-29T07:27:49.573123Z"
    }
   },
   "outputs": [],
   "source": [
    "a =  tf.reshape(a, [32, 128])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里有一个函数可以方便地返回静态形状，当静态可用而动态不可用的时候。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:28:48.791268Z",
     "start_time": "2018-03-29T07:28:48.785268Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_shape(tensor):\n",
    "    static_shape = tensor.get_shape().as_list()\n",
    "    dynamic_shape = tf.unstack(tf.shape(tensor))\n",
    "    dims = [s[1] if s[0] is None else s[0]\n",
    "            for s in zip(static_shape, dynamic_shape)]\n",
    "    return dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:29:20.940389Z",
     "start_time": "2018-03-29T07:29:20.934391Z"
    }
   },
   "source": [
    "现在想象一下，如果我们要将三维的张量转换成二维的张量。在 TensorFlow 中我们可以使用 `get_shape` m函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:58:20.152396Z",
     "start_time": "2018-03-29T07:58:20.137396Z"
    }
   },
   "outputs": [],
   "source": [
    "if a.dtype.char in np.typecodes['AllFloat']:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:58:20.922863Z",
     "start_time": "2018-03-29T07:58:20.913827Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "b = tf.random_normal([10, 32, 32, 3])\n",
    "shape = TensorShape(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:58:21.523195Z",
     "start_time": "2018-03-29T07:58:21.518167Z"
    }
   },
   "outputs": [],
   "source": [
    "b_ = shape.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-29T07:58:30.359615Z",
     "start_time": "2018-03-29T07:58:30.353569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 32, 32, 3]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T14:29:10.025067Z",
     "start_time": "2018-03-30T14:29:05.684051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.constant([[1., 2.], [3., 4.]])\n",
    "b = tf.constant([[1.], [2.]])\n",
    "\n",
    "c = a + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-30T14:29:13.630023Z",
     "start_time": "2018-03-30T14:29:10.044022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.220008850097656e-05\n"
     ]
    }
   ],
   "source": [
    "x = tf.random_normal([10])\n",
    "y = tf.nn.relu(x * x)\n",
    "with tf.Session():\n",
    "    diff = tf.test.compute_gradient_error(x, [10], y, [10])\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "author": "dd",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
