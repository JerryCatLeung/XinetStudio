{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建神经网络\n",
    "\n",
    "前面的教程我们教了大家如何实现线性回归，多类Logistic回归和多层感知机。我们既展示了如何从0开始实现，也提供使用 `gluon` 的更紧凑的实现。因为前面我们主要关注在模型本身，所以只解释了如何使用 `gluon`，但没说明他们是如何工作的。我们使用了 `nn.Sequential`，它是 `nn.Block` 的一个简单形式，但没有深入了解它们。\n",
    "\n",
    "本教程和接下来几个教程，我们将详细解释如何使用这两个类来定义神经网络、初始化参数、以及保存和读取模型。\n",
    "\n",
    "我们重新把`[多层感知机 --- 使用Gluon]`里的网络定义搬到这里作为开始的例子（为了简单起见，这里我们丢掉了 `Flatten` 层）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:50:04.734751Z",
     "start_time": "2018-03-06T12:50:04.731737Z"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "from mxnet.gluon import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:50:08.020831Z",
     "start_time": "2018-03-06T12:50:08.014831Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Dense(None -> 256, Activation(relu))\n",
      "  (1): Dense(None -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(256, activation=\"relu\"))\n",
    "    net.add(nn.Dense(10))\n",
    "\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 `nn.Block` 来定义\n",
    "\n",
    "事实上，`nn.Sequential`是`nn.Block`的简单形式。我们先来看下如何使用`nn.Block`来实现同样的网络。\n",
    "\n",
    "关于**类**的继承的方法——`super()`，参考：https://www.python-course.eu/python3_inheritance.php"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:50:09.881351Z",
     "start_time": "2018-03-06T12:50:09.860352Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marge Simpson\n",
      "Homer Simpson\n"
     ]
    }
   ],
   "source": [
    "class Person:\n",
    "    def __init__(self, first, last):\n",
    "        self.firstname = first\n",
    "        self.lastname = last\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.firstname + \" \" + self.lastname\n",
    "\n",
    "\n",
    "class Employee(Person):\n",
    "    def __init__(self, first, last, staffnum):\n",
    "        super().__init__(first, last)\n",
    "        self.staffnumber = staffnum\n",
    "\n",
    "\n",
    "x = Person(\"Marge\", \"Simpson\")\n",
    "y = Employee(\"Homer\", \"Simpson\", \"1007\")\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:51:22.986792Z",
     "start_time": "2018-03-06T12:51:22.979788Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense0 = nn.Dense(256)\n",
    "            self.dense1 = nn.Dense(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.dense1(nd.relu(self.dense0(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:51:23.791535Z",
     "start_time": "2018-03-06T12:51:23.787535Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (dense0): Dense(None -> 256, linear)\n",
      "  (dense1): Dense(None -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net2 = MLP()\n",
    "print(net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到`nn.Block`的使用是通过创建一个它子类的类，其中至少包含了两个函数。\n",
    "\n",
    "- `__init__`：创建参数。上面例子我们使用了包含了参数的`dense`层\n",
    "- `forward()`：定义网络的计算\n",
    "\n",
    "我们所创建的类的使用跟前面`net`没有太多不一样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:52:09.441084Z",
     "start_time": "2018-03-06T12:52:09.430081Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.03101084  0.02168356  0.0295247  -0.04508945  0.10636652 -0.01549807\n",
       "  -0.0193199  -0.0174359   0.08324829 -0.02836938]\n",
       " [ 0.02866082  0.0270328   0.04569576  0.0037463   0.05676579 -0.03816602\n",
       "  -0.02232858  0.00256437  0.03291164 -0.01463043]\n",
       " [ 0.01507498 -0.00986991  0.02329455  0.00512387  0.05632419 -0.04279632\n",
       "   0.00370564 -0.04851181  0.06240018 -0.00904769]\n",
       " [ 0.01429254 -0.01069933  0.0241727   0.01729557  0.05941372 -0.04356314\n",
       "   0.02740988 -0.03211071  0.04626468 -0.00124329]]\n",
       "<NDArray 4x10 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.initialize()\n",
    "x = nd.random.uniform(shape=(4,20))\n",
    "y = net2(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何定义创建和使用`nn.Dense`比较好理解。接下来我们仔细看下`MLP`里面用的其他命令：\n",
    "\n",
    "- `super(MLP, self).__init__(**kwargs)`：这句话调用`nn.Block`的`__init__`函数，它提供了`prefix`（指定名字）和`params`（指定模型参数）两个参数。我们会之后详细解释如何使用。\n",
    "\n",
    "- `self.name_scope()`：调用`nn.Block`提供的`name_scope()`函数。`nn.Dense`的定义放在这个`scope`里面。它的作用是给里面的所有层和参数的名字加上前缀（prefix）使得他们在系统里面独一无二。默认自动会自动生成前缀，我们也可以在创建的时候手动指定。推荐在构建网络时，每个层至少在一个`name_scope()`里。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:52:14.338606Z",
     "start_time": "2018-03-06T12:52:14.334598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default prefix: mlp2_dense0\n",
      "customized prefix: another_mlp_dense0\n"
     ]
    }
   ],
   "source": [
    "print('default prefix:', net2.dense0.name)\n",
    "\n",
    "net3 = MLP(prefix='another_mlp_')\n",
    "print('customized prefix:', net3.dense0.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大家会发现这里并没有定义如何求导，或者是`backward()`函数。事实上，系统会使用`autograd`对`forward()`自动生成对应的`backward()`函数。\n",
    "\n",
    "## `nn.Block`到底是什么东西？\n",
    "\n",
    "在`gluon`里，`nn.Block`是一个一般化的部件。整个神经网络可以是一个`nn.Block`，单个层也是一个`nn.Block`。我们可以（近似）无限地嵌套`nn.Block`来构建新的`nn.Block`。\n",
    "\n",
    "`nn.Block`主要提供这个东西\n",
    "\n",
    "1. 存储参数\n",
    "2. 描述`forward`如何执行\n",
    "3. 自动求导\n",
    "\n",
    "## 那么现在可以解释`nn.Sequential`了吧\n",
    "\n",
    "`nn.Sequential`是一个`nn.Block`容器，它通过`add`来添加`nn.Block`。它自动生成`forward()`函数，其就是把加进来的`nn.Block`逐一运行。\n",
    "\n",
    "一个简单的实现是这样的：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:55:13.602362Z",
     "start_time": "2018-03-06T12:55:13.592365Z"
    }
   },
   "outputs": [],
   "source": [
    "class Sequential(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def add(self, block):\n",
    "        self._children.append(block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for block in self._children:\n",
    "            x = block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以跟`nn.Sequential`一样的使用这个自定义的类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T12:55:47.134141Z",
     "start_time": "2018-03-06T12:55:47.119138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.02826474 -0.01304488 -0.02426514  0.00876594 -0.00851483  0.05259178\n",
       "   0.0324104   0.00798223 -0.08976573 -0.06062772]\n",
       " [ 0.01647029 -0.01826772 -0.00700102  0.01854971 -0.01967089  0.02673902\n",
       "   0.01536283 -0.00366282 -0.03796124 -0.05412994]\n",
       " [ 0.04295599  0.03146859  0.02592281  0.02170714 -0.03585934  0.05629688\n",
       "   0.04676364  0.02686935 -0.05454323 -0.03722154]\n",
       " [ 0.01240489  0.00070204  0.01789201  0.02881228 -0.03652953  0.01130896\n",
       "   0.01594532  0.02117223 -0.09650699 -0.03421253]]\n",
       "<NDArray 4x10 @cpu(0)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net4 = Sequential()\n",
    "with net4.name_scope():\n",
    "    net4.add(nn.Dense(256, activation=\"relu\"))\n",
    "    net4.add(nn.Dense(10))\n",
    "\n",
    "net4.initialize()\n",
    "y = net4(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，`nn.Sequential`的主要好处是定义网络起来更加简单。但`nn.Block`可以提供更加灵活的网络定义。考虑下面这个例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:22:54.218602Z",
     "start_time": "2018-03-06T14:22:54.181630Z"
    }
   },
   "outputs": [],
   "source": [
    "class FancyMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense = nn.Dense(256)\n",
    "            self.weight = nd.random_uniform(shape=(256,20))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nd.relu(self.dense(x))\n",
    "        x = nd.relu(nd.dot(x, self.weight)+1)\n",
    "        x = nd.relu(self.dense(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到这里我们直接手动创建和初始了权重`weight`，并重复用了`dense`的层。测试一下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:22:55.447688Z",
     "start_time": "2018-03-06T14:22:55.428692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 256)\n"
     ]
    }
   ],
   "source": [
    "fancy_mlp = FancyMLP()\n",
    "fancy_mlp.initialize()\n",
    "y = fancy_mlp(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `nn.Block`和`nn.Sequential`的嵌套使用\n",
    "\n",
    "现在我们知道了`nn`下面的类基本都是`nn.Block`的子类，他们可以很方便地嵌套使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-06T14:23:07.042135Z",
     "start_time": "2018-03-06T14:23:07.022144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): RecMLP(\n",
      "    (net): Sequential(\n",
      "      (0): Dense(None -> 256, Activation(relu))\n",
      "      (1): Dense(None -> 128, Activation(relu))\n",
      "    )\n",
      "    (dense): Dense(None -> 64, linear)\n",
      "  )\n",
      "  (1): Dense(None -> 10, linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "class RecMLP(nn.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.net = nn.Sequential()\n",
    "        with self.name_scope():\n",
    "            self.net.add(nn.Dense(256, activation=\"relu\"))\n",
    "            self.net.add(nn.Dense(128, activation=\"relu\"))\n",
    "            self.dense = nn.Dense(64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nd.relu(self.dense(self.net(x)))\n",
    "\n",
    "rec_mlp = nn.Sequential()\n",
    "rec_mlp.add(RecMLP())\n",
    "rec_mlp.add(nn.Dense(10))\n",
    "print(rec_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "不知道你同不同意，通过`nn.Block`来定义神经网络跟玩积木很类似。\n",
    "\n",
    "## 练习\n",
    "\n",
    "如果把`RecMLP`改成`self.denses = [nn.Dense(256), nn.Dense(128), nn.Dense(64)]`，`forward`就用for loop来实现，会有什么问题吗？\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/986)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
