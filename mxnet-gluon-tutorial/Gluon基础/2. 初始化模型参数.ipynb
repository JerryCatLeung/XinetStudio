{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初始化模型参数\n",
    "\n",
    "我们仍然用MLP这个例子来详细解释如何初始化模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:54:12.247831Z",
     "start_time": "2018-01-31T14:54:10.639668Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "c:\\anaconda3\\lib\\site-packages\\urllib3\\contrib\\pyopenssl.py:46: DeprecationWarning: OpenSSL.rand is deprecated - you should use os.urandom instead\n",
      "  import OpenSSL.SSL\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.Dense(4, activation=\"relu\"))\n",
    "        net.add(nn.Dense(2))\n",
    "    return net\n",
    "\n",
    "x = nd.random.uniform(shape=(3,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道如果不`initialize()`直接跑forward，那么系统会抱怨说参数没有初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:54:15.535576Z",
     "start_time": "2018-01-31T14:54:15.529571Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter sequential0_dense0_weight has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "try:\n",
    "    net = get_net()\n",
    "    net(x)\n",
    "except RuntimeError as err:\n",
    "    sys.stderr.write(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正确的打开方式是这样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:54:26.259097Z",
     "start_time": "2018-01-31T14:54:26.244057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[5.6932746e-03 5.3165095e-05]\n",
       " [3.9790268e-03 7.8816508e-04]\n",
       " [3.2033005e-03 1.5049987e-03]]\n",
       "<NDArray 3x2 @cpu(0)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 访问模型参数\n",
    "\n",
    "之前我们提到过可以通过`weight`和`bias`访问`Dense`的参数，他们是`Parameter`这个类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:55:40.122607Z",
     "start_time": "2018-01-31T14:55:40.117593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dense(5 -> 4, Activation(relu))\n",
       "  (1): Dense(4 -> 2, linear)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:55:49.009248Z",
     "start_time": "2018-01-31T14:55:49.005237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  sequential0_dense0 \n",
      "weight:  Parameter sequential0_dense0_weight (shape=(4, 5), dtype=<class 'numpy.float32'>) \n",
      "bias:  Parameter sequential0_dense0_bias (shape=(4,), dtype=<class 'numpy.float32'>)\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight\n",
    "b = net[0].bias\n",
    "print('name: ', net[0].name, '\\nweight: ', w, '\\nbias: ', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们可以通过`data`来访问参数，`grad`来访问对应的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:56:17.431151Z",
     "start_time": "2018-01-31T14:56:17.423131Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: \n",
      "[[ 0.01847461 -0.03004881 -0.02461551 -0.01465906 -0.05932271]\n",
      " [-0.0595007   0.0434817   0.04195441  0.05774786  0.00482907]\n",
      " [ 0.04922146  0.0243923  -0.06268584  0.04367422  0.03679534]\n",
      " [-0.06364554  0.03010933  0.05611894 -0.02152951  0.03825361]]\n",
      "<NDArray 4x5 @cpu(0)>\n",
      "weight gradient \n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "<NDArray 4x5 @cpu(0)>\n",
      "bias: \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n",
      "bias gradient \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "print('weight:', w.data())\n",
    "print('weight gradient', w.grad())\n",
    "print('bias:', b.data())\n",
    "print('bias gradient', b.grad())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们也可以通过`collect_params`来访问`Block`里面所有的参数（这个会包括所有的子`Block`）。它会返回一个名字到对应 `Parameter` 的 `dict`。既可以用正常`[]`来访问参数，也可以用`get()`，它不需要填写名字的前缀。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-31T14:57:02.022667Z",
     "start_time": "2018-01-31T14:57:02.016650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequential0_ (\n",
      "  Parameter sequential0_dense0_weight (shape=(4, 5), dtype=<class 'numpy.float32'>)\n",
      "  Parameter sequential0_dense0_bias (shape=(4,), dtype=<class 'numpy.float32'>)\n",
      "  Parameter sequential0_dense1_weight (shape=(2, 4), dtype=<class 'numpy.float32'>)\n",
      "  Parameter sequential0_dense1_bias (shape=(2,), dtype=<class 'numpy.float32'>)\n",
      ")\n",
      "\n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n",
      "\n",
      "[[ 0.01847461 -0.03004881 -0.02461551 -0.01465906 -0.05932271]\n",
      " [-0.0595007   0.0434817   0.04195441  0.05774786  0.00482907]\n",
      " [ 0.04922146  0.0243923  -0.06268584  0.04367422  0.03679534]\n",
      " [-0.06364554  0.03010933  0.05611894 -0.02152951  0.03825361]]\n",
      "<NDArray 4x5 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "params = net.collect_params()\n",
    "print(params)\n",
    "print(params['sequential0_dense0_bias'].data())\n",
    "print(params.get('dense0_weight').data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用不同的初始函数来初始化\n",
    "\n",
    "我们一直在使用默认的`initialize`来初始化权重（除了指定GPU `ctx`外）。它会把所有权重初始化成在`[-0.07, 0.07]`之间均匀分布的随机数。我们可以使用别的初始化方法。例如使用均值为$0$，方差为$0.02$的正态分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.00956226  0.01925707  0.03457717  0.0084907   0.03445733]\n",
      " [-0.00640247 -0.01956459  0.04135118 -0.03433602  0.0094062 ]\n",
      " [ 0.00486903  0.00600536  0.03815848  0.00139216 -0.00589869]\n",
      " [ 0.02499754 -0.0393823  -0.03443903 -0.01360089 -0.0066522 ]]\n",
      "<NDArray 4x5 @cpu(0)> \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "from mxnet import init\n",
    "params.initialize(init=init.Normal(sigma=0.02), force_reinit=True)\n",
    "print(net[0].weight.data(), net[0].bias.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看得更加清楚点："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n",
      "<NDArray 4x5 @cpu(0)> \n",
      "[0. 0. 0. 0.]\n",
      "<NDArray 4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "params.initialize(init=init.One(), force_reinit=True)\n",
    "print(net[0].weight.data(), net[0].bias.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多的方法参见[init的API](https://mxnet.incubator.apache.org/api/python/optimization.html#the-mxnet-initializer-package). \n",
    "\n",
    "## 延后的初始化\n",
    "\n",
    "我们之前提到过Gluon的一个便利的地方是模型定义的时候不需要指定输入的大小，在之后做forward的时候会自动推测参数的大小。我们具体来看这是怎么工作的。\n",
    "\n",
    "新创建一个网络，然后打印参数。你会发现两个全连接层的权重的形状里都有$0$。 这是因为在不知道输入数据的情况下，我们无法判断它们的形状。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential1_ (\n",
       "  Parameter sequential1_dense0_weight (shape=(4, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense0_bias (shape=(4,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense1_weight (shape=(2, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense1_bias (shape=(2,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = get_net()\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential1_ (\n",
       "  Parameter sequential1_dense0_weight (shape=(4, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense0_bias (shape=(4,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense1_weight (shape=(2, 0), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense1_bias (shape=(2,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.initialize()\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你会看到我们形状并没有发生变化，这是因为我们仍然不能确定权重形状。真正的初始化发生在我们看到数据时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sequential1_ (\n",
       "  Parameter sequential1_dense0_weight (shape=(4, 5), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense0_bias (shape=(4,), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense1_weight (shape=(2, 4), dtype=<class 'numpy.float32'>)\n",
       "  Parameter sequential1_dense1_bias (shape=(2,), dtype=<class 'numpy.float32'>)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(x)\n",
    "net.collect_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这时候我们看到 shape 里面的 $0$ 被填上正确的值了。\n",
    "\n",
    "## 共享模型参数\n",
    "\n",
    "有时候我们想在层之间共享同一份参数，我们可以通过Block的`params`输出参数来手动指定参数，而不是让系统自动生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(4, activation=\"relu\"))\n",
    "    net.add(nn.Dense(4, activation=\"relu\"))\n",
    "    net.add(nn.Dense(4, activation=\"relu\", params=net[-1].params))\n",
    "    net.add(nn.Dense(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化然后打印"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.00146846  0.06708457  0.00377706 -0.02985603]\n",
      " [ 0.03104883 -0.05449805 -0.06617871  0.02707522]\n",
      " [-0.0626184   0.06622557 -0.03636756  0.06569055]\n",
      " [-0.05142071  0.04123941 -0.02823606 -0.05013531]]\n",
      "<NDArray 4x4 @cpu(0)>\n",
      "\n",
      "[[ 0.00146846  0.06708457  0.00377706 -0.02985603]\n",
      " [ 0.03104883 -0.05449805 -0.06617871  0.02707522]\n",
      " [-0.0626184   0.06622557 -0.03636756  0.06569055]\n",
      " [-0.05142071  0.04123941 -0.02823606 -0.05013531]]\n",
      "<NDArray 4x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "net(x)\n",
    "print(net[1].weight.data())\n",
    "print(net[2].weight.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义初始化方法\n",
    "\n",
    "下面我们自定义一个初始化方法。它通过重载`_init_weight`来实现不同的初始化方法。（注意到Gluon里面`bias`都是默认初始化成0）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init weight (4, 5)\n",
      "init weight (2, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "[[7.056691  5.0810294 9.799772  6.01421   9.655567 ]\n",
       " [5.9796658 5.5281696 7.142277  8.7071905 7.8319225]\n",
       " [5.1681466 7.7171893 5.0255055 6.5666866 9.039704 ]\n",
       " [5.1865773 8.613197  7.329293  9.926311  8.418011 ]]\n",
       "<NDArray 4x5 @cpu(0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyInit(init.Initializer):\n",
    "    def __init__(self):\n",
    "        super(MyInit, self).__init__()\n",
    "        self._verbose = True\n",
    "    def _init_weight(self, _, arr):\n",
    "        # 初始化权重，使用out=arr后我们不需指定形状\n",
    "        print('init weight', arr.shape)\n",
    "        nd.random.uniform(low=5, high=10, out=arr)\n",
    "\n",
    "net = get_net()\n",
    "net.initialize(MyInit())\n",
    "net(x)\n",
    "net[0].weight.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当然我们也可以通过`Parameter.set_data`来直接改写权重。注意到由于有延后初始化，所以我们通常可以通过调用一次`net(x)`来确定权重的形状先。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default weight: \n",
      "[[-0.01560705  0.01619106 -0.04681858 -0.0483556 ]\n",
      " [ 0.05755728  0.0293365   0.05690721  0.06266605]]\n",
      "<NDArray 2x4 @cpu(0)>\n",
      "init to all 1s: \n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "<NDArray 2x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "net = get_net()\n",
    "net.initialize()\n",
    "net(x)\n",
    "\n",
    "print('default weight:', net[1].weight.data())\n",
    "\n",
    "w = net[1].weight\n",
    "w.set_data(nd.ones(w.shape))\n",
    "\n",
    "print('init to all 1s:', net[1].weight.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "我们可以很灵活地访问和修改模型参数。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 研究下`net.collect_params()`返回的是什么？`net.params`呢？\n",
    "1. 如何对每个层使用不同的初始化函数\n",
    "1. 如果两个层共用一个参数，那么求梯度的时候会发生什么？\n",
    "\n",
    "**吐槽和讨论欢迎点**[这里](https://discuss.gluon.ai/t/topic/987)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
